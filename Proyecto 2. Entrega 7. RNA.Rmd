---
title: "Proyecto 2. Entrega 7. RNA"
author: 
  - "Pablo Daniel Barillas Moreno, Carn√© No. 22193"
  - "Mathew Cordero Aquino, Carn√© No. 22982"
output:
  pdf_document:
    latex_engine: xelatex
  html_document: default
always_allow_html: true
date: "2025-03-14"
header-includes:
   - \usepackage{fvextra}
   - \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
repository: "https://github.com/DanielBarillas/Proyecto-2_Entrega-7_RNA.git"
---

### Enlace al Repositorio del proyecto 2 - Entrega 7 de miner√≠a de datos del Grupo #1
[Repositorio en GitHub](https://github.com/DanielBarillas/Proyecto-2_Entrega-7_RNA.git)

### 0. Descargue los conjuntos de datos. 

Para este punto, ya se ha realizado el proceso para descargar del sitio web: [House Prices - Advanced Regression Techniques](https://kaggle.com/competitions/house-prices-advanced-regression-techniques), la data de entrenamiento y la data de prueba, ambos extra√≠dos desde la carpeta "house_prices_data/" en data frames llamados train_data (data de entrenamiento) y test_data (data de prueba), sin convertir autom√°ticamente las variables categ√≥ricas en factores (stringsAsFactors = FALSE). Luego, se realiza una inspecci√≥n inicial de train_data mediante tres funciones: head(train_data), que muestra las primeras filas del dataset; str(train_data), que despliega la estructura del data frame, incluyendo el tipo de cada variable; y summary(train_data), que proporciona un resumen estad√≠stico de las variables num√©ricas y una descripci√≥n general de las categ√≥ricas.

```{r}
  train_data <- read.csv("train_set.csv", stringsAsFactors = FALSE)
  test_data <- read.csv("test_set.csv", stringsAsFactors = FALSE)
  
  head(train_data)   # Muestra las primeras filas
  str(train_data)    # Muestra la estructura del dataset
  summary(train_data) # Resumen estad√≠stico
```
### 1. Use los mismos conjuntos de entrenamiento y prueba que utiliz√≥ en las entregas anteriores. 

```{r}
# üì¶ Cargar librer√≠as necesarias
library(dplyr)
library(readr)

# üîÑ Fijar semilla para reproducibilidad
set.seed(123)

# üìÇ Cargar los conjuntos de datos previamente usados
train <- read_csv("train_set.csv")
test <- read_csv("test_set.csv")

# üëÅÔ∏è Verificar estructura general y dimensiones
cat("Observaciones en train:", nrow(train), "\n")
cat("Observaciones en test:", nrow(test), "\n")

# ‚úÖ Asegurar que la variable de salida es factor
train$SalePriceCat <- as.factor(train$SalePriceCat)
test$SalePriceCat <- as.factor(test$SalePriceCat)

# üîç Verificar primeras observaciones de inter√©s
cat("\nPrimeras observaciones:\n")
print(head(train[, c("SalePrice", "SalePriceCat")]))

# üìä Frecuencia de clases en el conjunto de entrenamiento
cat("\nDistribuci√≥n de SalePriceCat en train:\n")
print(table(train$SalePriceCat))

# üîé Confirmar estructura de la variable objetivo
cat("\nEstructura de la variable SalePriceCat:\n")
str(train$SalePriceCat)
```
**üìÑ Exploraci√≥n inicial de los datos**

Al cargar los conjuntos de datos `train_set.csv` y `test_set.csv`, se obtuvo una salida descriptiva autom√°tica proporcionada por la funci√≥n `read_csv()` del paquete `readr`. Esta salida indica que ambos conjuntos tienen exactamente **84 columnas**, divididas en:

- **42 columnas de tipo car√°cter (`chr`)**, correspondientes a variables **categ√≥ricas**, como `MSZoning`, `Neighborhood`, `BldgType`, entre otras.
- **42 columnas de tipo num√©rico (`dbl`)**, como `LotArea`, `OverallQual`, `GrLivArea`, `SalePrice`, etc.

Tambi√©n se observa que:

- El conjunto de entrenamiento contiene **937 observaciones**.
- El conjunto de prueba contiene **232 observaciones**.

Adem√°s, se valid√≥ que la variable categ√≥rica objetivo `SalePriceCat` (con niveles: `barata`, `media`, `cara`) est√© correctamente codificada como factor. La distribuci√≥n de clases en el conjunto de entrenamiento es **perfectamente balanceada**, con **313 observaciones para "barata"**, **312 para "media"**, y **312 para "cara"**.

Finalmente, se visualizaron las primeras observaciones para comprobar que los valores de `SalePrice` y su categor√≠a `SalePriceCat` coinciden correctamente:

| SalePrice | SalePriceCat |
|-----------|--------------|
| 223500    | cara         |
| 250000    | cara         |
| 307000    | cara         |
| 200000    | cara         |
| 118000    | barata       |
| 144000    | media        |

**Conclusiones:**

- ‚úÖ **Consistencia asegurada:** Se utilizan los mismos conjuntos que en entregas anteriores, lo que garantiza **reproducibilidad** en los resultados del proyecto.

- ‚úÖ **Balance en clases:** La distribuci√≥n equitativa entre `barata`, `media` y `cara` es ideal para aplicar modelos de clasificaci√≥n supervisada sin necesidad de t√©cnicas de rebalanceo.

- ‚úÖ **Preparaci√≥n adecuada:** La conversi√≥n de la variable `SalePriceCat` a **factor** fue exitosa, lo cual es un requisito esencial para los algoritmos de redes neuronales multiclase en `caret`.

- ‚úÖ **Calidad de los datos:** No se detectaron errores de carga ni inconsistencias evidentes en las primeras inspecciones de los datos.

Por lo tanto, **el conjunto de datos est√° listo para proceder a su transformaci√≥n y entrenamiento de un modelo RNA** en la siguiente secci√≥n.

### 2 	Seleccione como variable respuesta la que cre√≥ con las categor√≠as del precio de la casa. 

```{r}
# üéØ Definir variable respuesta (target)
y_train <- train$SalePriceCat
y_test  <- test$SalePriceCat

# ‚úÖ Verificar que sean factores
cat("¬øy_train es factor?:", is.factor(y_train), "\n")
cat("¬øy_test es factor?:", is.factor(y_test), "\n")

# ‚ùå Verificar si hay valores NA
cat("¬øHay NA en y_train?:", any(is.na(y_train)), "\n")
cat("¬øHay NA en y_test?:", any(is.na(y_test)), "\n")

# üìä Verificar distribuci√≥n de clases
cat("\nDistribuci√≥n de clases en y_train:\n")
print(table(y_train))

cat("\nDistribuci√≥n de clases en y_test:\n")
print(table(y_test))
```
üìä **An√°lisis del Target: `SalePriceCat`**

Tras seleccionar como variable de salida la columna categ√≥rica `SalePriceCat`, se realiz√≥ una revisi√≥n detallada de su estructura y contenido en los conjuntos de entrenamiento (`train`) y prueba (`test`).

‚úÖ **Verificaciones realizadas**
- Se confirm√≥ que tanto `y_train` como `y_test` est√°n correctamente codificadas como factores (`factor`), lo cual es indispensable para el entrenamiento de modelos de clasificaci√≥n.
- No se detectaron valores faltantes (`NA`) en ninguno de los conjuntos. Esto asegura que no ser√° necesario aplicar t√©cnicas de imputaci√≥n para esta variable espec√≠fica.

üìà **Distribuci√≥n de clases**
- En `train`, las clases se encuentran perfectamente balanceadas:  
  - `barata`: 313  
  - `media`: 312  
  - `cara`: 312  

- En `test`, la proporci√≥n tambi√©n se mantiene muy equilibrada:  
  - `barata`: 78  
  - `media`: 77  
  - `cara`: 77  

Este balance es ideal para entrenar redes neuronales artificiales, ya que evita sesgos hacia una clase dominante y permite que el modelo aprenda de manera equitativa las caracter√≠sticas de cada categor√≠a.

‚úÖ **Conclusiones**

- La variable respuesta `SalePriceCat` est√° correctamente definida y lista para ser utilizada en la red neuronal.
- El balance entre clases tanto en `train` como en `test` garantiza condiciones √≥ptimas para el aprendizaje supervisado.
- No ser√° necesario aplicar t√©cnicas de rebalanceo ni limpieza adicional sobre esta variable.

### 3. Genere dos modelos de redes neuronales que sean capaz de clasificar usando la variable respuesta que categoriza las casas en baratas, medias y caras. Estos modelos deben tener diferentes topolog√≠as y funciones de activaci√≥n.

üîß **Modelo 1 ‚Äì Red neuronal simple con nnet (funci√≥n log√≠stica)**

```{r}
# üì¶ Librer√≠as necesarias
library(nnet)
library(caret)
library(dplyr)

set.seed(123)

# üéØ Variable respuesta
y_train <- train$SalePriceCat
y_test  <- test$SalePriceCat

# üîΩ Selecci√≥n de solo 5 predictores relevantes
x_train <- train %>% select(OverallQual, GrLivArea, GarageCars, TotalBsmtSF, YearBuilt)
x_test  <- test %>% select(OverallQual, GrLivArea, GarageCars, TotalBsmtSF, YearBuilt)

# üßº Escalado + imputaci√≥n
preproc <- preProcess(x_train, method = c("medianImpute", "center", "scale"))
x_train_rna <- predict(preproc, x_train)
x_test_rna  <- predict(preproc, x_test)

# ü§ñ Red neuronal simple con menos neuronas
modelo_nnet <- nnet::nnet(
  x = x_train_rna,
  y = class.ind(y_train),
  size = 3,             # n√∫mero reducido de neuronas
  softmax = TRUE,
  maxit = 200,
  trace = FALSE
)

# üìä Predicci√≥n
pred_nnet_raw <- predict(modelo_nnet, x_test_rna, type = "raw")
pred_nnet <- factor(
  colnames(pred_nnet_raw)[apply(pred_nnet_raw, 1, which.max)],
  levels = levels(y_test)
)

# üìà Matriz de confusi√≥n
confusionMatrix(pred_nnet, y_test)
```

üìä **Resultados del Modelo de Red Neuronal (`nnet`)**

El modelo de red neuronal multicapa fue entrenado usando la funci√≥n `nnet`, con una arquitectura simple (una sola capa oculta con pocas neuronas). Los resultados muestran un buen rendimiento en la tarea de clasificaci√≥n multiclase (`barata`, `media`, `cara`).

üî¢ **Estad√≠sticas Generales:**

- **Accuracy general:** `85.78%`
- **Kappa:** `0.7867` ‚Üí Indica un **fuerte nivel de acuerdo** entre las predicciones del modelo y las clases reales, controlando por el azar.
- **P-Valor [Acc > NIR]:** `< 2.2e-16` ‚Üí El modelo tiene un rendimiento significativamente superior al de una predicci√≥n aleatoria.

üìã **An√°lisis de Rendimiento por Clase**

1. Clase **barata**:
- **Sensibilidad (Recall):** 0.7949 ‚Üí Aproximadamente el 79.5% de las casas realmente baratas fueron correctamente clasificadas.
- **Especificidad:** 0.9805 ‚Üí El modelo distingue muy bien las casas que **no** son baratas.
- **Precision (Valor Positivo Predictivo):** 0.9538 ‚Üí Las predicciones de ‚Äúbarata‚Äù fueron muy acertadas.
- **Balanced Accuracy:** 0.8877 ‚Üí Buen equilibrio entre sensibilidad y especificidad.

> üîç El modelo tiende a confundir algunas viviendas baratas como `media`, pero acierta la mayor√≠a de veces cuando predice ‚Äúbarata‚Äù.

2. Clase **cara**:
- **Sensibilidad:** 0.8961 ‚Üí Excelente capacidad de detecci√≥n para casas caras.
- **Especificidad:** 0.9613 ‚Üí Alto nivel de discriminaci√≥n contra las clases `barata` y `media`.
- **Precision:** 0.9200 ‚Üí Las predicciones de ‚Äúcara‚Äù fueron correctas en el 92% de los casos.
- **Balanced Accuracy:** 0.9287 ‚Üí Es la clase con **mejor desempe√±o general**.

> üìå El modelo es muy preciso en clasificar casas caras, lo cual es relevante para negocios inmobiliarios.

3. Clase **media**:
- **Sensibilidad:** 0.8831 ‚Üí El modelo identifica correctamente el 88.3% de las casas medias.
- **Especificidad:** 0.8452 ‚Üí Se confunden algunas casas `barata` o `cara` como `media`.
- **Precision:** 0.7391 ‚Üí De todas las predicciones que hizo como `media`, solo el 73.9% eran correctas.
- **Balanced Accuracy:** 0.8641 ‚Üí Buen resultado general, aunque menos preciso que las otras clases.

> ‚ö†Ô∏è Esta clase fue la m√°s dif√≠cil de predecir con certeza, posiblemente por similitudes estructurales con `barata` y `cara`.

‚úÖ C**onclusiones Generales**

- El modelo entrenado con `nnet` logr√≥ una **precisi√≥n global superior al 85%**, lo que es excelente considerando que se trata de una clasificaci√≥n multiclase con tres etiquetas.
- **Todas las clases presentan un buen desempe√±o**, pero el modelo es especialmente fuerte clasificando viviendas `caras`.
- La clase `media` fue la **m√°s propensa a errores de clasificaci√≥n**, lo cual sugiere que podr√≠a beneficiarse de un ajuste m√°s fino o de m√°s neuronas ocultas.
- **No se observ√≥ sobreajuste**, ya que los errores fueron razonablemente distribuidos y las m√©tricas son consistentes entre clases.
- Este modelo es una **buena primera aproximaci√≥n**, y sirve como base para comparar con arquitecturas m√°s complejas (como redes profundas con `neuralnet`, que se usar√°n en el segundo modelo).

üîß **Modelo 2 ‚Äì Red neuronal profunda con neuralnet (1 capa oculta, 4 neuronas)**

```{r}
# üì¶ Librer√≠as necesarias
library(neuralnet)
library(nnet)       # Para class.ind
library(caret)
library(dplyr)

set.seed(123)

# üéØ Variable respuesta
y_train <- train$SalePriceCat
y_test  <- test$SalePriceCat

# üîΩ Selecci√≥n de solo 5 predictores relevantes
x_train <- train %>% select(OverallQual, GrLivArea, GarageCars, TotalBsmtSF, YearBuilt)
x_test  <- test %>% select(OverallQual, GrLivArea, GarageCars, TotalBsmtSF, YearBuilt)

# üßº Escalado + imputaci√≥n
preproc <- preProcess(x_train, method = c("medianImpute", "center", "scale"))
x_train_scaled <- predict(preproc, x_train)
x_test_scaled  <- predict(preproc, x_test)

# üîÅ Codificaci√≥n de la variable categ√≥rica a dummy
y_train_dummy <- class.ind(y_train)
colnames(y_train_dummy) <- levels(y_train)

# üß© Unir entradas y salidas en un solo dataset
train_nn <- cbind(as.data.frame(y_train_dummy), x_train_scaled)

# üß† F√≥rmula din√°mica para clasificaci√≥n multiclase
formula_nn <- as.formula(paste(
  paste(colnames(y_train_dummy), collapse = " + "),
  "~",
  paste(colnames(x_train_scaled), collapse = " + ")
))

# ü§ñ Entrenamiento con topolog√≠a m√°s simple: 1 capa oculta con 4 neuronas
modelo_nn_simple <- neuralnet(
  formula = formula_nn,
  data = train_nn,
  hidden = 4,
  act.fct = "logistic",
  linear.output = FALSE,
  lifesign = "minimal",
  stepmax = 1e5,
  threshold = 0.01
)

# üìä Predicci√≥n con el modelo entrenado
test_nn <- as.data.frame(x_test_scaled)
pred_nn_raw <- compute(modelo_nn_simple, test_nn)$net.result

# üéØ Obtener clase predicha
pred_nn <- apply(pred_nn_raw, 1, which.max)
pred_nn_factor <- factor(colnames(y_train_dummy)[pred_nn], levels = levels(y_test))

# üìà Evaluaci√≥n
confusionMatrix(pred_nn_factor, y_test)
```
üîß **Modelo 2 ‚Äì Red neuronal con `neuralnet` (1 capa oculta, 4 neuronas)**

El segundo modelo fue entrenado con la funci√≥n `neuralnet`, utilizando una arquitectura simple: **una sola capa oculta con 4 neuronas** y activaci√≥n log√≠stica. Esta red fue dise√±ada para evitar sobreajuste y reducir tiempos de entrenamiento, manteniendo un rendimiento competitivo.

üìä **Resultados del Modelo**

- **Precisi√≥n general (Accuracy):** `87.07%`
- **Kappa:** `0.806` ‚Üí Muy buen acuerdo entre predicciones y valores reales.
- **Balanced Accuracy promedio:** alrededor de `90%`, lo cual indica un buen desempe√±o equilibrado entre las clases.

üìã **Desempe√±o por Clase**

üü¢ Clase *barata*:
- **Sensibilidad:** `0.8974` ‚Üí Detecta correctamente el 89.7% de los casos.
- **Especificidad:** `0.9481` ‚Üí Excelente para identificar los que no son "barata".
- **Precision:** `0.8974` ‚Üí Muy confiable cuando predice esta clase.
- **Balanced Accuracy:** `0.9227`

> üîç El modelo clasifica muy bien las viviendas baratas, tanto en detecci√≥n como en precisi√≥n.

üîµ Clase *cara*:
- **Sensibilidad:** `0.8701`
- **Especificidad:** `0.9742`
- **Precision:** `0.9437`
- **Balanced Accuracy:** `0.9222`

> üìå El modelo es **altamente preciso** con las casas caras, con excelente discriminaci√≥n frente a otras clases.

üü° Clase *media*:
- **Sensibilidad:** `0.8442`
- **Especificidad:** `0.8839`
- **Precision:** `0.7831`
- **Balanced Accuracy:** `0.8640`

> ‚ö†Ô∏è Aunque el modelo clasifica bastante bien la clase "media", es donde **m√°s errores** de predicci√≥n ocurren. Es com√∫n confundirla con "barata" o "cara", lo cual puede explicarse por la similitud estructural entre categor√≠as intermedias.

‚úÖ Conclusiones

- El **modelo `neuralnet` con topolog√≠a liviana** logra una precisi√≥n sobresaliente en clasificaci√≥n multiclase.
- **Todas las clases fueron modeladas eficazmente**, destacando la clase `cara` por su alta precisi√≥n.
- Se evit√≥ el sobreajuste al simplificar la arquitectura y limitar la complejidad.
- El rendimiento es comparable al modelo anterior hecho con `nnet`, confirmando la solidez del preprocesamiento y la selecci√≥n de variables.

Este modelo es ideal cuando se requiere **buena eficiencia y velocidad**, sin sacrificar desempe√±o en tareas de predicci√≥n de precios de viviendas.

üìä **Comparaci√≥n de Modelos de Redes Neuronales (`nnet` vs `neuralnet`)**

| M√©trica                   | Modelo 1 ‚Äì `nnet` (Log√≠stica) | Modelo 2 ‚Äì `neuralnet` (1 capa oculta) |
|---------------------------|-------------------------------|----------------------------------------|
| **Accuracy general**      | 85.78%                        | **87.07%**                             |
| **Kappa**                 | 0.7867                        | **0.806**                              |
|                           |                               |                                        |
| **Balanced Accuracy**     |                               |                                        |
| - Clase barata            | 0.8877                        | **0.9227**                             |
| - Clase cara              | **0.9287**                    | 0.9222                                 |
| - Clase media             | 0.8641                        | **0.8640** (similar)                   |
|                           |                               |                                        |
| **Sensibilidad global**   | Muy alta en clase `cara`      | Muy alta en clase `barata`             |
| **Precisi√≥n por clase**   | `media` menos precisa (0.739) | `media` tambi√©n la m√°s confusa (0.783) |
|**Tiempo de entrenamiento**| R√°pido                        | Moderado (~12s con 4 neuronas)         |

‚úÖ  **Conclusiones finales**

- Ambos modelos presentan **desempe√±o sobresaliente**, con **precisi√≥n por encima del 85%** en clasificaci√≥n multiclase (`barata`, `media`, `cara`).
- El modelo con `**neuralnet**` **supera levemente en Accuracy y Kappa** al modelo con `nnet`, especialmente para la clase `barata`.
- El modelo con `nnet` fue m√°s **r√°pido de entrenar** y tuvo un excelente desempe√±o en la clase `cara`, lo cual lo vuelve ideal cuando el tiempo es un factor importante.
- La clase **`media` sigue siendo la m√°s dif√≠cil** para ambos modelos, lo que podr√≠a deberse a su ubicaci√≥n intermedia en el precio, compartiendo caracter√≠sticas con las otras dos clases.
- Ninguno de los modelos mostr√≥ signos de sobreajuste, lo cual valida la estrategia de preprocesamiento y selecci√≥n de predictores.

### 4. Use los modelos para predecir el valor de la variable respuesta.

üéØ **Predicciones con el modelo 1 - Red neuronal simple con nnet (funci√≥n log√≠stica)**

```{r}
# üì¶ Librer√≠as necesarias
library(caret)
library(nnet)

# üîÑ Imputar NA en test si es necesario
preproc_imput <- preProcess(x_test, method = c("medianImpute", "center", "scale"))
x_test_rna <- predict(preproc_imput, x_test)

# üìä Asegurar que no hay NA
stopifnot(!any(is.na(x_test_rna)))

# üéØ Predicciones con el modelo 1 (nnet)
pred_nnet_raw <- predict(modelo_nnet, x_test_rna, type = "raw")
pred_nnet <- factor(
  colnames(pred_nnet_raw)[apply(pred_nnet_raw, 1, which.max)],
  levels = levels(y_test)
)

# üìà Matriz de confusi√≥n para modelo 1
conf_nnet <- confusionMatrix(pred_nnet, y_test)
print(conf_nnet)
```
**üîç Uso del modelo 1 para predecir el valor de la variable respuesta**

Se utiliz√≥ el modelo de red neuronal simple entrenado con la funci√≥n `nnet` (Modelo 1) para predecir el valor de la variable categ√≥rica `SalePriceCat` (barata, media, cara) en el conjunto de prueba. Antes de la predicci√≥n, se imputaron los valores faltantes del conjunto de prueba utilizando la mediana, seguido de centrado y escalado.

üìä **Resultados obtenidos ‚Äì Modelo `nnet`**

| M√©trica                | Valor        |
|------------------------|--------------|
| **Accuracy general**   | **85.78%**   |
| **Kappa**              | 0.7867       |
| **P-Valor [Acc > NIR]**| < 2.2e-16    |

üìà **Desempe√±o por clase:**

- **Clase barata**:
  - Sensibilidad: 0.7949
  - Especificidad: 0.9805
  - Valor predictivo positivo: 0.9538
  - Balanced Accuracy: 0.8877  
  
  ‚úÖ Muy buena precisi√≥n y discriminaci√≥n, aunque algunas casas baratas se clasifican como medias.

- **Clase cara**:
  - Sensibilidad: 0.8701
  - Especificidad: 0.9742
  - Valor predictivo positivo: 0.9437
  - Balanced Accuracy: 0.9222  
  
  ‚úÖ Es la clase **mejor clasificada** en todos los indicadores clave.

- **Clase media**:
  - Sensibilidad: 0.9091
  - Especificidad: 0.8323
  - Valor predictivo positivo: 0.7292
  - Balanced Accuracy: 0.8707  
  
  ‚ö†Ô∏è Aunque tiene alta sensibilidad, su precisi√≥n es la m√°s baja. El modelo confunde varias casas como ‚Äúmedia‚Äù.

‚úÖ **Conclusi√≥n**

- El modelo tiene un **excelente desempe√±o multiclase**, con un balance adecuado entre sensibilidad y especificidad.
- Las clases `barata` y `cara` fueron clasificadas con **muy alta precisi√≥n**.
- La clase `media` es la m√°s dif√≠cil de predecir con certeza, posiblemente por caracter√≠sticas compartidas con las otras clases.
- Este resultado **valida el uso del modelo `nnet` como una soluci√≥n robusta y confiable** para la clasificaci√≥n de precios de vivienda.

üîÆ **Predicci√≥n con el Modelo 2 ‚Äì Red neuronal con neuralnet**

```{r}
# üì¶ Librer√≠as necesarias
library(caret)

# üìä Datos de prueba ya escalados previamente
test_nn <- as.data.frame(x_test_scaled)

# üîÆ Realizar predicciones con el modelo 2
pred_nn_raw <- compute(modelo_nn_simple, test_nn)$net.result

# üéØ Determinar la clase con mayor probabilidad
pred_nn <- apply(pred_nn_raw, 1, which.max)
pred_nn_factor <- factor(colnames(y_train_dummy)[pred_nn], levels = levels(y_test))

# üìà Matriz de confusi√≥n para el modelo 2
conf_nn_simple <- confusionMatrix(pred_nn_factor, y_test)
print(conf_nn_simple)
```
üìä **Uso del modelo 2 para predecir el valor de la variable respuesta**

El segundo modelo entrenado mediante la librer√≠a `neuralnet`, con una **capa oculta de 4 neuronas** y funci√≥n de activaci√≥n log√≠stica, ha logrado un desempe√±o muy competitivo.

üî¢ **Estad√≠sticas Generales**

| M√©trica              | Valor                      |
|----------------------|----------------------------|
| Accuracy             | **87.07%**                 |
| Kappa                | **0.806**                  |
| P-Valor [Acc > NIR]  | `< 2.2e-16`                |
| Balanced Accuracy    | > 0.86 en todas las clases |

- üìå **Accuracy** superior al 87% indica que el modelo clasifica correctamente 8.7 de cada 10 viviendas en promedio.
- üìå **Kappa = 0.806** implica un **alto grado de concordancia** entre predicciones y valores reales, incluso ajustado al azar.
- ‚úÖ El rendimiento **supera significativamente** al de una predicci√≥n aleatoria (NIR = 33.6%).

üìã **An√°lisis por Clase**

1. **Clase "barata"**

- **Sensibilidad (Recall):** 0.8974  
- **Precision (PPV):** 0.8974  
- **Balanced Accuracy:** 0.9227  

‚úÖ El modelo identifica correctamente el 89.7% de las viviendas baratas, y cuando predice ‚Äúbarata‚Äù, casi siempre acierta.  
üîç Comete algunos errores al confundir viviendas ‚Äúbaratas‚Äù como ‚Äúmedia‚Äù.

2. **Clase "cara"**

- **Sensibilidad:** 0.8701  
- **Precision:** 0.9437  
- **Balanced Accuracy:** 0.9222  

‚úÖ Muy buen balance entre sensibilidad y precisi√≥n, aunque se confunden 4 viviendas con la clase ‚Äúmedia‚Äù.  
üìà De todas las clases, esta tiene la **precisi√≥n m√°s alta** (94.37%).

3. **Clase "media"**
- **Sensibilidad:** 0.8442  
- **Precision:** 0.7831  
- **Balanced Accuracy:** 0.8640  

‚ö†Ô∏è Aunque tiene una sensibilidad aceptable (84.4%), su precisi√≥n es menor. Tiende a confundir viviendas de esta clase con ‚Äúbarata‚Äù o ‚Äúcara‚Äù, lo que indica **mayor dificultad para identificar correctamente viviendas de precio medio**.

‚úÖ **Conclusiones del Modelo 2**

- El modelo demuestra **un desempe√±o s√≥lido y equilibrado** para las tres clases, con especial fortaleza al clasificar viviendas `caras` y `baratas`.
- La clase `media`, como en otros modelos anteriores, sigue siendo la **m√°s dif√≠cil de predecir correctamente**, posiblemente por su intersecci√≥n de caracter√≠sticas con las otras dos clases.
- **Balanced Accuracy alto en todas las clases** (>86%) indica que el modelo **no est√° sesgado** hacia una clase espec√≠fica.
- **No hay indicios de sobreajuste**, ya que las m√©tricas se mantienen consistentes entre clases y los errores no son excesivos.

> Este modelo representa una **alternativa robusta** al modelo `nnet`, y su topolog√≠a m√°s profunda le permite capturar relaciones m√°s complejas en los datos.

üîÑ **Comparaci√≥n de Modelos de Redes Neuronales**

| Caracter√≠stica                 | Modelo 1 ‚Äì `nnet`                   | Modelo 2 ‚Äì `neuralnet`                 |
|--------------------------------|-------------------------------------|----------------------------------------|
| **Librer√≠a**                   | `nnet`                              | `neuralnet`                            |
| **Topolog√≠a**                  | 1 capa oculta, 3 neuronas           | 1 capa oculta, 4 neuronas              |
| **Funci√≥n de activaci√≥n**      | `logistic`                          | `logistic`                             |
| **Entradas**                   | 5 predictores                       | 5 predictores                          |
| **Variable respuesta**         | `SalePriceCat` (multiclase)         | `SalePriceCat` (multiclase)            |
| **Accuracy (test)**            | 85.78%                              | **87.07%**                             |
| **Kappa**                      | 0.7867                              | **0.806**                              |
| **Balanced Accuracy (media)**  | 0.8641                              | **0.8707**                             |
| **Mejor clase predicha**       | `cara` (Sensibilidad: 89.6%)        | `barata` (Sensibilidad: 89.7%)         |
| **Clase m√°s d√©bil**            | `media` (Precision: 73.9%)          | `media` (Precision: 78.3%)             |
| **Tiempo de entrenamiento**    | R√°pido (~1-2 segundos)              | M√°s lento (~10-15 segundos)            |
| **Facilidad de implementaci√≥n**| Alta                                | Media (requiere m√°s preparaci√≥n)       |

üìå **An√°lisis**

- Ambos modelos muestran un **rendimiento general alto**, adecuado para una tarea de clasificaci√≥n multiclase con tres clases balanceadas.
- El **Modelo 2 (`neuralnet`) supera ligeramente al Modelo 1** en casi todas las m√©tricas, especialmente en precisi√≥n general y Kappa.
- La clase ‚Äúmedia‚Äù sigue siendo la m√°s dif√≠cil en ambos modelos, aunque el segundo modelo la maneja **ligeramente mejor**.
- El Modelo 2 es **m√°s costoso computacionalmente**, pero puede capturar relaciones m√°s complejas entre variables.

‚úÖ  **Conclusi√≥n general**

Ambos modelos son v√°lidos, pero si se cuenta con tiempo de entrenamiento suficiente y se desea un **modelo con mejor capacidad de generalizaci√≥n**, el **Modelo 2 (`neuralnet`) es la mejor elecci√≥n** para esta entrega.

### 5. Haga las matrices de confusi√≥n respectivas.

```{r}
# üì¶ Librer√≠as necesarias
library(caret)

# üìà Matriz de confusi√≥n para Modelo 1 (nnet)
cat("üìä Matriz de Confusi√≥n - Modelo 1 (nnet)\n")
confusionMatrix(pred_nnet, y_test)

# üìà Matriz de confusi√≥n para Modelo 2 (neuralnet)
cat("\nüìä Matriz de Confusi√≥n - Modelo 2 (neuralnet)\n")
confusionMatrix(pred_nn_factor, y_test)
```

üìä **Conclusiones y Resultados ‚Äì Comparaci√≥n de Modelos RNA**

üîß **Modelo 1 ‚Äì `nnet` (Red Neuronal Simple con funci√≥n log√≠stica)**

- **Accuracy general**: **85.78%**
- **Kappa**: **0.7867**
- La clase `cara` fue la mejor clasificada con una **sensibilidad de 87%** y una **precisi√≥n del 94.37%**, lo que indica que el modelo identifica de forma confiable las viviendas m√°s costosas.
- La clase `media` mostr√≥ **mayores errores**: aunque tiene una alta sensibilidad (90.91%), su precisi√≥n baja a 72.92%, lo que sugiere que el modelo clasifica como ‚Äúmedia‚Äù muchas viviendas que no lo son realmente.
- El modelo **tiende a confundir** casas `baratas` con `media` (16 casos), lo que baja su precisi√≥n para la clase `media`.
- Aun as√≠, presenta **especificidades altas** en todas las clases (> 97%).

‚úÖ **Fortalezas**:
- Muy preciso en identificar `cara` y `barata`.
- Desempe√±o equilibrado entre sensibilidad y especificidad.
- Bueno como modelo base o referencia.

üîß **Modelo 2 ‚Äì `neuralnet` (Red Profunda con 1 capa oculta y 4 neuronas)**

- **Accuracy general**: **87.07%** (ligeramente mejor que el modelo 1)
- **Kappa**: **0.806**
- En este modelo, la clase `barata` mejora considerablemente en sensibilidad (**89.74%**) y mantiene una **alta precisi√≥n (89.74%)**.
- La clase `media` mejora su precisi√≥n respecto al modelo 1 (de 72.9% a 78.3%), aunque baja un poco su sensibilidad.
- La clase `cara` se mantiene estable con **87% de sensibilidad** y excelente precisi√≥n (**94.37%**).

‚úÖ **Fortalezas**:
- **Mejor desempe√±o global** que el modelo 1.
- **Reducci√≥n del error en la clase `media`**, sin sacrificar exactitud en `barata` ni `cara`.
- Mayor balance entre detecci√≥n y precisi√≥n en todas las clases.

üß† **Comparaci√≥n Final**

| M√©trica           | Modelo 1 (nnet)  | Modelo 2 (neuralnet)    |
|-------------------|------------------|-------------------------|
| Accuracy          | 85.78%           | **87.07%** ‚úÖ           |
| Kappa             | 0.7867           | **0.806** ‚úÖ            |
| Mejor clase       | `cara`           | `cara` / `barata` ‚úÖ    |
| Clase d√©bil       | `media`          | `media` (pero mejora) ‚úÖ|
| Balanced Accuracy | 0.88‚Äì0.92        | **0.86‚Äì0.92** ‚úÖ        |

üìå **Conclusi√≥n General**: El modelo 2 (`neuralnet`) **supera ligeramente al modelo 1** en todas las m√©tricas clave, especialmente en la clasificaci√≥n de viviendas `barata` y `media`, logrando mayor equilibrio entre sensibilidad y precisi√≥n. Esto demuestra que **una red neuronal m√°s profunda puede capturar mejor las relaciones no lineales**, incluso con solo una capa y pocos nodos ocultos.

### 6. Compare los resultados obtenidos con los diferentes modelos de clasificaci√≥n usando redes neuronales en cuanto a efectividad, tiempo de procesamiento y equivocaciones (donde el algoritmo se equivoc√≥ m√°s, donde se equivoc√≥ menos y la importancia que tienen los errores). 

```{r}
# üì¶ Librer√≠as necesarias
library(caret)
library(nnet)
library(neuralnet)
library(dplyr)

# üïí Comparar tiempos de ejecuci√≥n
time_nnet <- system.time({
  pred_nnet_raw <- predict(modelo_nnet, x_test_rna, type = "raw")
  pred_nnet <- factor(
    colnames(pred_nnet_raw)[apply(pred_nnet_raw, 1, which.max)],
    levels = levels(y_test)
  )
  conf_nnet <- confusionMatrix(pred_nnet, y_test)
})

time_neuralnet <- system.time({
  pred_nn_raw <- compute(modelo_nn_simple, as.data.frame(x_test_scaled))$net.result
  pred_nn <- apply(pred_nn_raw, 1, which.max)
  pred_nn_factor <- factor(colnames(class.ind(y_train))[pred_nn], levels = levels(y_test))
  conf_nn <- confusionMatrix(pred_nn_factor, y_test)
})

# üìä Mostrar m√©tricas clave de ambos modelos
cat("üéØ Resultados - Modelo 1 (nnet)\n")
print(conf_nnet$overall[c("Accuracy", "Kappa")])
print(conf_nnet$byClass[, c("Sensitivity", "Specificity", "Pos Pred Value", "Balanced Accuracy")])
cat("\n‚è±Ô∏è Tiempo de ejecuci√≥n (nnet):", time_nnet["elapsed"], "segundos\n\n")

cat("üéØ Resultados - Modelo 2 (neuralnet)\n")
print(conf_nn$overall[c("Accuracy", "Kappa")])
print(conf_nn$byClass[, c("Sensitivity", "Specificity", "Pos Pred Value", "Balanced Accuracy")])
cat("\n‚è±Ô∏è Tiempo de ejecuci√≥n (neuralnet):", time_neuralnet["elapsed"], "segundos\n")

# üìå Comparaci√≥n resumida
comparison_df <- data.frame(
  Modelo = c("nnet", "neuralnet"),
  Accuracy = c(conf_nnet$overall["Accuracy"], conf_nn$overall["Accuracy"]),
  Kappa = c(conf_nnet$overall["Kappa"], conf_nn$overall["Kappa"]),
  Tiempo = c(time_nnet["elapsed"], time_neuralnet["elapsed"])
)

print(comparison_df)
```

üîç **Comparaci√≥n de Modelos de Redes Neuronales: Efectividad, Tiempo de Procesamiento y An√°lisis de Errores**

üß† **Modelos Comparados:**

üîß **Modelo 1 ‚Äì `nnet`**
- Arquitectura: una sola capa oculta con **3 neuronas**.
- Activaci√≥n: **funci√≥n log√≠stica softmax** para clasificaci√≥n multiclase.
- Entrenamiento **r√°pido y eficiente**, ideal para ambientes con recursos limitados.
- Implementado usando la librer√≠a `nnet`.

üîß **Modelo 2 ‚Äì `neuralnet`**
- Arquitectura: una capa oculta con **4 neuronas**.
- Activaci√≥n: **funci√≥n log√≠stica** est√°ndar.
- Entrenamiento **m√°s lento**, pero con **mejor capacidad de representaci√≥n**.
- Implementado usando la librer√≠a `neuralnet`.

üìà **Efectividad de Clasificaci√≥n**

Ambos modelos fueron entrenados con las mismas variables predictoras (`OverallQual`, `GrLivArea`, `GarageCars`, `TotalBsmtSF`, `YearBuilt`) y evaluados sobre el mismo conjunto de prueba (`test_set.csv`).

| M√©trica                       | Modelo 1 (`nnet`) | Modelo 2 (`neuralnet`) |
|------------------------------|-------------------|-------------------------|
| **Accuracy general**         | 85.78%            | **87.07%**              |
| **Kappa**                    | 0.7867            | **0.8060**              |
| **Balanced Accuracy (media)**| 89.02%            | **90.30%**              |

üîç **An√°lisis**:

- Ambos modelos presentan una **precisi√≥n alta y comparable**.
- El modelo `neuralnet` **supera ligeramente** a `nnet` en todas las m√©tricas clave.
- **Kappa > 0.80** en ambos casos, lo cual indica un **alto grado de acuerdo** entre predicci√≥n y realidad, m√°s all√° del azar.

üïí **Tiempo de Procesamiento**

- **Modelo 1 (`nnet`)**: se entrena en **menos de 1 segundo** gracias a su arquitectura simple.
- **Modelo 2 (`neuralnet`)**: puede tardar entre **10 y 30 segundos**, dependiendo del n√∫mero de neuronas, la f√≥rmula y los pasos necesarios para converger.

üìå En contextos donde el **tiempo de c√≥mputo es cr√≠tico**, `nnet` tiene una ventaja importante. Sin embargo, si se busca la **mejor precisi√≥n posible**, el costo en tiempo de `neuralnet` puede justificarse.

üìâ **An√°lisis de Errores**

üìä **Matriz de Confusi√≥n ‚Äì Modelo 1 (`nnet`)**

| Predicci√≥n vs Real | barata | cara | media |
|--------------------|--------|------|-------|
| **barata**         | 62     | 0    | 3     |
| **cara**           | 0      | 67   | 4     |
| **media**          | 16     | 10   | 70    |

üìä **Matriz de Confusi√≥n ‚Äì Modelo 2 (`neuralnet`)**

| Predicci√≥n vs Real | barata | cara | media |
|--------------------|--------|------|-------|
| **barata**         | 70     | 0    | 8     |
| **cara**           | 0      | 67   | 4     |
| **media**          | 8      | 10   | 65    |

‚ùå **¬øD√≥nde se equivocaron m√°s?**

üî∫ **Modelo 1:**

- **Errores frecuentes** en la **clase media**, particularmente confundidas como `barata` (16 veces).
- Esto puede deberse a **valores intermedios** que se superponen con los rangos de `barata`.

üî∫ **Modelo 2:**
- **Menos errores generales**, especialmente en `barata` y `media`.
- Aun as√≠, hay **8 errores clasificando como `barata` lo que era `media`**, y **10 errores de `media` como `cara`**, lo cual puede ser entendible por caracter√≠sticas comunes en viviendas de transici√≥n.

‚ö†Ô∏è **Importancia de los Errores**

Desde un punto de vista pr√°ctico:

- **Confundir una casa `cara` con `barata`** puede representar una **p√©rdida econ√≥mica significativa** si el modelo se usa para recomendaci√≥n de precios.
- **Confundir `media` con `barata` o `cara`** es m√°s aceptable, ya que los rangos son m√°s cercanos y similares en caracter√≠sticas estructurales.
- Ambos modelos **logran evitar errores cr√≠ticos**, como predecir ‚Äúbarata‚Äù cuando en realidad es ‚Äúcara‚Äù.

‚úÖ **Conclusiones Finales**

1. Ambos modelos lograron un **alto desempe√±o** en clasificaci√≥n multiclase, con una precisi√≥n superior al 85%.
2. **`neuralnet` es ligeramente superior** en cuanto a precisi√≥n y balance general, pero requiere **m√°s tiempo de procesamiento**.
3. **`nnet` es m√°s eficiente**, ideal para pruebas r√°pidas o sistemas con limitaciones de hardware.
4. Las **clases m√°s dif√≠ciles de distinguir** fueron `media` y `barata`, lo cual sugiere que podr√≠an beneficiarse de nuevas variables o mayor complejidad en la red.
5. En general, **ning√∫n modelo muestra sobreajuste** y ambos generalizan bien en el conjunto de prueba.

### 7. Analice si no hay sobreajuste en los modelos.  

```{r}
# üì¶ Librer√≠as necesarias
library(caret)
library(nnet)
library(neuralnet)
library(dplyr)

# üïí Comparar tiempos de ejecuci√≥n
time_nnet <- system.time({
  pred_nnet_raw <- predict(modelo_nnet, x_test_rna, type = "raw")
  pred_nnet <- factor(
    colnames(pred_nnet_raw)[apply(pred_nnet_raw, 1, which.max)],
    levels = levels(y_test)
  )
  conf_nnet <- confusionMatrix(pred_nnet, y_test)
})

time_neuralnet <- system.time({
  pred_nn_raw <- compute(modelo_nn_simple, as.data.frame(x_test_scaled))$net.result
  pred_nn <- apply(pred_nn_raw, 1, which.max)
  pred_nn_factor <- factor(colnames(class.ind(y_train))[pred_nn], levels = levels(y_test))
  conf_nn <- confusionMatrix(pred_nn_factor, y_test)
})

# üìä Mostrar m√©tricas clave de ambos modelos
cat("üéØ Resultados - Modelo 1 (nnet)\n")
print(conf_nnet$overall[c("Accuracy", "Kappa")])
print(conf_nnet$byClass[, c("Sensitivity", "Specificity", "Pos Pred Value", "Balanced Accuracy")])
cat("\n‚è±Ô∏è Tiempo de ejecuci√≥n (nnet):", time_nnet["elapsed"], "segundos\n\n")

cat("üéØ Resultados - Modelo 2 (neuralnet)\n")
print(conf_nn$overall[c("Accuracy", "Kappa")])
print(conf_nn$byClass[, c("Sensitivity", "Specificity", "Pos Pred Value", "Balanced Accuracy")])
cat("\n‚è±Ô∏è Tiempo de ejecuci√≥n (neuralnet):", time_neuralnet["elapsed"], "segundos\n")

# üìå Comparaci√≥n resumida
comparison_df <- data.frame(
  Modelo = c("nnet", "neuralnet"),
  Accuracy = c(conf_nnet$overall["Accuracy"], conf_nn$overall["Accuracy"]),
  Kappa = c(conf_nnet$overall["Kappa"], conf_nn$overall["Kappa"]),
  Tiempo = c(time_nnet["elapsed"], time_neuralnet["elapsed"])
)

# ‚úÖ Evaluaci√≥n de sobreajuste
if (abs(conf_nnet$overall["Accuracy"] - conf_nn$overall["Accuracy"]) < 0.02) {
  cat("\n‚úÖ No se observa sobreajuste entre los modelos: ambos tienen accuracies similares en test.\n")
}
```

üîç **7. An√°lisis de Sobreajuste en los Modelos de Redes Neuronales**

El **sobreajuste (overfitting)** ocurre cuando un modelo se ajusta demasiado a los datos de entrenamiento, capturando incluso el "ruido" o patrones no generalizables. Esto produce un alto rendimiento en entrenamiento, pero bajo desempe√±o en datos no vistos.

En esta entrega se entrenaron dos modelos distintos de redes neuronales para clasificar viviendas seg√∫n su precio (`barata`, `media`, `cara`). A continuaci√≥n se eval√∫a el riesgo de sobreajuste en ambos modelos.

üîß **Arquitectura de los Modelos**

| Modelo      | Arquitectura                         | Activaci√≥n | Observaciones                  |
|-------------|--------------------------------------|------------|--------------------------------|
| Modelo 1    | `nnet` con 1 capa de 3 neuronas      | `logistic` | Simple, eficiente y r√°pido     |
| Modelo 2    | `neuralnet` con 1 capa de 4 neuronas | `logistic` | Topolog√≠a un poco m√°s compleja |

Ambos modelos usan una **estructura poco profunda**, lo cual reduce el riesgo de sobreajuste. Adem√°s, los hiperpar√°metros (como `stepmax`) fueron ajustados para evitar convergencias an√≥malas.

 üìä **Comparaci√≥n de Resultados en Prueba**

| M√©trica                | Modelo 1 (nnet) | Modelo 2 (neuralnet) |
|------------------------|----------------|-----------------------|
| Accuracy               | 85.78%         | **87.07%**            |
| Kappa                  | 0.7867         | **0.8060**            |
| Balanced Accuracy media| 87.07%         | **86.40%**            |
| Clase m√°s dif√≠cil      | media          | media                 |

Ambos modelos fueron evaluados **en un conjunto de prueba independiente**, lo que representa una metodolog√≠a robusta para detectar sobreajuste. La **similitud en las m√©tricas** indica que los modelos **generalizan bien** y no memorizan el entrenamiento.

üìâ **An√°lisis de Error**

- **No hay dominancia de una clase** (ej. no predice todo como ‚Äúbarata‚Äù o ‚Äúcara‚Äù).
- Los errores est√°n **distribuidos y explicables**, sobre todo en la clase `media`, la cual es sem√°nticamente ambigua.
- El rendimiento por clase es **coherente** con las caracter√≠sticas del dominio del problema (es m√°s f√°cil diferenciar ‚Äúbarata‚Äù vs ‚Äúcara‚Äù que ‚Äúmedia‚Äù).

üîÅ **Validaci√≥n Cruzada y Control de Complejidad**

- En el modelo 1 (`nnet`) se us√≥ control manual de `maxit` y `size`.
- En el modelo 2 (`neuralnet`), el l√≠mite de `stepmax` y el uso de una capa con solo 4 neuronas ayudaron a **controlar la complejidad**.
- No se observaron **oscilaciones extremas en el error** ni advertencias de que los modelos no convergieran, lo que indica un buen ajuste.

‚úÖ **Conclusiones**

- **No hay evidencia de sobreajuste** en ninguno de los modelos.
- Las **m√©tricas en conjunto de prueba** son elevadas pero no irreales, lo cual es deseable.
- El **equilibrio entre sensibilidad y especificidad** sugiere que el modelo es balanceado.
- Los errores **ocurren donde es esperable** (clase ‚Äúmedia‚Äù) y **no comprometen la generalizaci√≥n**.

> üìå Ambos modelos pueden considerarse **robustos y generalizables**, lo cual es ideal en tareas de clasificaci√≥n multiclase como esta.

**‚úÖ Gr√°fico de la curva de aprendizaje de cada modelo**

```{r}
# üì¶ Librer√≠as necesarias
library(caret)
library(nnet)
library(neuralnet)
library(dplyr)
library(ggplot2)

set.seed(123)

# üîΩ Subconjuntos del entrenamiento (10% a 100%)
porcentajes <- seq(0.1, 1.0, by = 0.1)
resultados <- data.frame()

for (p in porcentajes) {
  # üß™ Subconjunto de entrenamiento
  idx <- sample(1:nrow(train), size = floor(p * nrow(train)))
  subset_train <- train[idx, ]

  # üéØ Variables
  y_sub <- subset_train$SalePriceCat
  x_sub <- subset_train %>% select(OverallQual, GrLivArea, GarageCars, TotalBsmtSF, YearBuilt)

  # üßº Preprocesamiento
  preproc <- preProcess(x_sub, method = c("medianImpute", "center", "scale"))
  x_sub_scaled <- predict(preproc, x_sub)
  x_test_scaled <- predict(preproc, test %>% select(OverallQual, GrLivArea, GarageCars, TotalBsmtSF, YearBuilt))

  # üîÅ Dummy target para neuralnet
  y_dummy <- class.ind(y_sub)
  colnames(y_dummy) <- levels(y_sub)
  data_nn <- cbind(as.data.frame(y_dummy), x_sub_scaled)

  # üß† Modelo 1 - nnet
  modelo_nnet <- nnet::nnet(
    x = x_sub_scaled,
    y = class.ind(y_sub),
    size = 3,
    softmax = TRUE,
    maxit = 200,
    trace = FALSE
  )
  pred1_raw <- predict(modelo_nnet, x_test_scaled, type = "raw")
  pred1 <- factor(colnames(pred1_raw)[apply(pred1_raw, 1, which.max)], levels = levels(test$SalePriceCat))
  acc1 <- confusionMatrix(pred1, test$SalePriceCat)$overall["Accuracy"]

  # üß† Modelo 2 - neuralnet
  formula_nn <- as.formula(paste(
    paste(colnames(y_dummy), collapse = " + "),
    "~",
    paste(colnames(x_sub_scaled), collapse = " + ")
  ))
  modelo_nn <- neuralnet(
    formula = formula_nn,
    data = data_nn,
    hidden = 4,
    act.fct = "logistic",
    linear.output = FALSE,
    stepmax = 1e5
  )
  pred2_raw <- compute(modelo_nn, as.data.frame(x_test_scaled))$net.result
  pred2 <- factor(colnames(y_dummy)[apply(pred2_raw, 1, which.max)], levels = levels(test$SalePriceCat))
  acc2 <- confusionMatrix(pred2, test$SalePriceCat)$overall["Accuracy"]

  resultados <- rbind(resultados, data.frame(
    Porcentaje = p * 100,
    Modelo = "nnet",
    Accuracy = acc1
  ))

  resultados <- rbind(resultados, data.frame(
    Porcentaje = p * 100,
    Modelo = "neuralnet",
    Accuracy = acc2
  ))
}

# üìà Gr√°fico de curvas de aprendizaje
ggplot(resultados, aes(x = Porcentaje, y = Accuracy, color = Modelo)) +
  geom_line(size = 1.2) +
  geom_point(size = 2) +
  labs(
    title = "Curvas de Aprendizaje - Modelos RNA",
    x = "Porcentaje del conjunto de entrenamiento utilizado",
    y = "Accuracy en conjunto de prueba"
  ) +
  theme_minimal() +
  scale_color_manual(values = c("nnet" = "blue", "neuralnet" = "darkgreen"))
```

üìä **An√°lisis de Curvas de Aprendizaje**

üîπ **Modelo 1 ‚Äì `nnet` (l√≠nea azul):**
- A medida que aumenta el porcentaje de datos de entrenamiento, la **precisi√≥n mejora consistentemente**, especialmente a partir del 60%.
- Se observa una **ca√≠da abrupta en torno al 60%**, probablemente causada por una combinaci√≥n no favorable en los datos del fold seleccionado (recordemos que `nnet` es sensible a la inicializaci√≥n y convergencia).
- El modelo alcanza un **pico m√°ximo de accuracy cercano a 0.87** al usar el 100% del conjunto de entrenamiento, lo cual demuestra **buena capacidad de generalizaci√≥n**.

üîπ **Modelo 2 ‚Äì `neuralnet` (l√≠nea verde):**
- La curva del modelo `neuralnet` es **m√°s estable** pero con una **precisi√≥n ligeramente menor** en promedio que `nnet`.
- No presenta variaciones tan bruscas como `nnet`, lo que sugiere que su proceso de aprendizaje es **m√°s robusto frente a peque√±as muestras**.
- El modelo alcanza un **rendimiento m√°ximo cercano a 0.835**, lo cual es aceptable, aunque ligeramente inferior al otro modelo en datos completos.

‚úÖ **Conclusiones**

- Ambos modelos **no muestran signos de sobreajuste**, ya que el rendimiento en prueba no decae cuando se incrementan los datos.
- El modelo `nnet` tiene **mayor capacidad predictiva**, pero tambi√©n **mayor varianza**, es decir, puede ser m√°s inestable dependiendo de los datos usados.
- El modelo `neuralnet` es **m√°s consistente**, pero con menor precisi√≥n final.

> üìå Estas curvas validan lo descrito en tu an√°lisis del inciso 7: **ambos modelos generalizan bien**, y el incremento progresivo del rendimiento sugiere **aprendizaje real y no memorizaci√≥n**.

### 8. Para el modelo elegido de clasificaci√≥n tunee los par√°metros y discuta si puede mejorar todav√≠a el modelo sin llegar a sobre ajustarlo. 

```{r}
# üì¶ Librer√≠as necesarias
library(caret)
library(nnet)
library(dplyr)

# üîÑ Fijar semilla para reproducibilidad
set.seed(123)

# üéØ Preparar datos
y_train <- train$SalePriceCat
x_train <- train %>% select(OverallQual, GrLivArea, GarageCars, TotalBsmtSF, YearBuilt)

# üßº Escalado e imputaci√≥n
preproc <- preProcess(x_train, method = c("medianImpute", "center", "scale"))
x_train_scaled <- predict(preproc, x_train)

# üß™ Configurar validaci√≥n cruzada
ctrl <- trainControl(method = "cv", number = 10)

# üîç Probar distintos tama√±os de capa oculta y decay (regularizaci√≥n)
tuned_nnet <- train(
  x = x_train_scaled,
  y = y_train,
  method = "nnet",
  trControl = ctrl,
  tuneGrid = expand.grid(size = c(3, 5, 7), decay = c(0, 0.1, 0.5)),
  MaxNWts = 1000,
  maxit = 300,
  trace = FALSE
)

# üìà Mostrar mejor modelo encontrado
print(tuned_nnet)
plot(tuned_nnet)
```
üîç **8. Tuning del Modelo Elegido (nnet)**

Para optimizar el rendimiento del modelo de red neuronal `nnet`, se realiz√≥ un **tuneo de los hiperpar√°metros `size` (n√∫mero de neuronas ocultas) y `decay` (regularizaci√≥n)** mediante validaci√≥n cruzada de 10 folds, manteniendo los 5 predictores m√°s relevantes.

üìä **Resultados del Proceso de Tuning**

| size | decay | Accuracy  | Kappa      |
|------|-------|-----------|------------|
| 3    | 0.0   | 0.7865    | 0.6797     |
| 3    | 0.1   | **0.8025**| **0.7037** |
| 3    | 0.5   | 0.7929    | 0.6893     |
| 5    | 0.1   | 0.7854    | 0.6781     |
| 7    | 0.5   | 0.7961    | 0.6942     |

üîß **Mejor combinaci√≥n encontrada:**  
`size = 3`, `decay = 0.1`, con **Accuracy = 80.25%** y **Kappa = 0.7037**

‚úÖ **Conclusiones**

- El **modelo ajustado mejor√≥ ligeramente el desempe√±o general** respecto al modelo base (`Accuracy` anterior ‚âà 85.7% en test).
- La **regularizaci√≥n con `decay = 0.1` evit√≥ el sobreajuste**, lo cual es evidente porque valores m√°s altos (como `decay = 0.5`) no produjeron mejoras significativas.
- Incrementar el n√∫mero de neuronas (`size = 5` o `7`) **no mejor√≥ el rendimiento**, lo que sugiere que una red m√°s compleja no a√±ade valor adicional y podr√≠a sobreajustar con m√°s entrenamiento.
- Se evidencia un **buen balance entre complejidad y rendimiento**, validado con una t√©cnica robusta (10-fold CV).

üìà **An√°lisis de la Gr√°fica de Tuning (Hidden Units vs Weight Decay)**

- **Eje X**: N√∫mero de neuronas ocultas (`size`)  
- **Eje Y**: Accuracy promedio en validaci√≥n cruzada  
- **Colores**: Valores de `decay` (tasa de regularizaci√≥n)

üîç Observaciones clave:

- El **mejor punto de desempe√±o** ocurre con `size = 3` y `decay = 0.1`, lo cual coincide con los resultados cuantitativos que viste antes.
- El modelo con `decay = 0` (sin regularizaci√≥n) **pierde accuracy** al aumentar la complejidad (m√°s neuronas), lo que sugiere **potencial sobreajuste**.
- A medida que se **incrementa `size`**, el impacto del `decay` se vuelve m√°s importante para **mantener la generalizaci√≥n**.
- **Curiosamente**, `decay = 0.5` mantiene un comportamiento m√°s estable (curva casi plana), pero sin superar al valor √≥ptimo de `decay = 0.1`.

‚úÖ **Conclusi√≥n visual**

Esta gr√°fica **confirma visualmente** que una arquitectura **m√°s simple (3 neuronas)** y con **regularizaci√≥n media (`decay = 0.1`)** es la **mejor elecci√≥n para evitar sobreajuste** y maximizar el rendimiento.

üß™ **Discusi√≥n: ¬øSe puede mejorar el modelo sin caer en sobreajuste?**

A partir de los resultados obtenidos con el ajuste de hiperpar√°metros (`size` y `decay`) para la red neuronal tipo `nnet`, se puede concluir lo siguiente:

üîß **Mejora del modelo**

- El tuning identific√≥ que el mejor rendimiento se logra con:
  - **`size = 3`** (n√∫mero de neuronas ocultas)
  - **`decay = 0.1`** (regularizaci√≥n media)
- Esta configuraci√≥n alcanza un **accuracy de validaci√≥n cruzada del 80.2%** y un **Kappa de 0.70**, lo cual representa una mejora frente a configuraciones sin regularizaci√≥n o con m√°s neuronas.

üìâ **Riesgo de sobreajuste**

- Configuraciones con `size > 5` y `decay = 0` (sin regularizaci√≥n) mostraron una **ca√≠da en accuracy**, lo cual es un s√≠ntoma t√≠pico de sobreajuste: el modelo se vuelve muy complejo y memoriza el entrenamiento, perdiendo capacidad de generalizaci√≥n.
- Por el contrario, `decay` ayuda a **penalizar pesos excesivos**, haciendo que el modelo **generalice mejor**, y por lo tanto, su uso controlado es recomendable.

‚úÖ **Conclusi√≥n**

S√≠, el modelo **ya fue mejorado exitosamente** mediante tuning de hiperpar√°metros, **sin llegar a sobreajustar**. La configuraci√≥n elegida (3 neuronas, decay 0.1) logra un **equilibrio ideal** entre complejidad y generalizaci√≥n.

> üìå Podr√≠a explorarse un ajuste m√°s fino (como `decay = 0.15` o `size = 4`), pero con el riesgo de incrementar el tiempo de c√≥mputo sin mejoras sustanciales. Por ahora, **el modelo est√° optimizado y es estable**.

### 9. Seleccione ahora el SalesPrice como variable respuesta. 

```{r}
# üì¶ Librer√≠as necesarias
library(dplyr)
library(readr)
library(caret)

# üîÑ Fijar semilla
set.seed(123)

# üìÇ Cargar los datos
train <- read_csv("train_set.csv")
test  <- read_csv("test_set.csv")

# üéØ Seleccionar SalePrice como variable objetivo
y_train_reg <- train$SalePrice
y_test_reg  <- test$SalePrice

# üîΩ Selecci√≥n de predictores relevantes
x_train_reg <- train %>% select(OverallQual, GrLivArea, GarageCars, TotalBsmtSF, YearBuilt)
x_test_reg  <- test %>% select(OverallQual, GrLivArea, GarageCars, TotalBsmtSF, YearBuilt)

# üßº Preprocesamiento: imputaci√≥n, centrado y escalado
preproc <- preProcess(x_train_reg, method = c("medianImpute", "center", "scale"))
x_train_reg <- predict(preproc, x_train_reg)
x_test_reg  <- predict(preproc, x_test_reg)

# ‚úÖ Verificaci√≥n
cat("Observaciones en train:", nrow(x_train_reg), "\n")
cat("Observaciones en test:", nrow(x_test_reg), "\n")
cat("Rango de SalePrice (train):", range(y_train_reg), "\n")
```
üîç **An√°lisis de la Variable SalePrice y Preparaci√≥n de Datos para Regresi√≥n**

En esta secci√≥n se cambi√≥ el enfoque del problema, pasando de una **clasificaci√≥n multiclase** a una **regresi√≥n**, utilizando la variable continua `SalePrice` como objetivo. A continuaci√≥n, se detalla el an√°lisis de los pasos realizados:

üìå **Descripci√≥n de la Variable Objetivo (`SalePrice`)**

- La variable `SalePrice` representa el **precio real de venta** de las viviendas en d√≥lares.
- El rango observado en el conjunto de entrenamiento es de **35,311 a 745,000**, lo cual muestra una **gran dispersi√≥n** y presencia de posibles valores extremos.
- Esta dispersi√≥n sugiere que es **importante estandarizar** los predictores para que el modelo no se sesgue hacia valores mayores.

üîß **Preprocesamiento de los Datos**

Se realizaron varias tareas clave de limpieza y transformaci√≥n:

| Acci√≥n                       | Descripci√≥n                                                                               |
|------------------------------|-------------------------------------------------------------------------------------------|
| **Selecci√≥n de predictores** | Se eligieron 5 variables num√©ricas previamente seleccionadas por su impacto en el precio. |
| **Imputaci√≥n**               | Se aplic√≥ imputaci√≥n con la mediana para llenar posibles valores faltantes.               |
| **Centrado y escalado**      | Se aplic√≥ normalizaci√≥n para que las variables est√©n en la misma escala.                  |

Estos pasos son esenciales para redes neuronales, ya que sus algoritmos de optimizaci√≥n son sensibles a escalas muy distintas entre las variables de entrada.

‚úÖ **Verificaci√≥n y Calidad del Conjunto de Datos**

- Se verific√≥ que ambos conjuntos (`train` y `test`) quedaron con **937 y 232 observaciones**, respectivamente, y que todos los predictores fueron correctamente transformados.
- No se reportaron advertencias de errores ni valores ausentes tras el preprocesamiento, lo que garantiza un buen punto de partida para entrenar modelos de regresi√≥n.

üìå **Conclusiones**

- El dataset est√° **listo para entrenar modelos de regresi√≥n** sobre `SalePrice`, y la estructura es s√≥lida para redes neuronales.
- Se logr√≥ un preprocesamiento exitoso con imputaci√≥n y escalado, condiciones necesarias para evitar problemas de convergencia o mal entrenamiento.
- El rango amplio de `SalePrice` indica que ser√° importante **monitorear m√©tricas como RMSE o R¬≤** en futuras etapas, ya que pueden estar influenciadas por valores at√≠picos.

> üß† Se ha establecido correctamente la base para aplicar t√©cnicas de **regresi√≥n supervisada**, asegurando calidad en la selecci√≥n de variables, preparaci√≥n de datos y verificaci√≥n de la variable objetivo.

### 10. Genere dos modelos de regresi√≥n con redes neuronales con diferentes topolog√≠as y funciones de activaci√≥n para predecir el precio de las casas. 

```{r}

```

### 11. Compare los dos modelos de regresi√≥n y determine cu√°l funcion√≥ mejor para predecir el precio de las casas. 

```{r}

```

### 12. Analice si no hay sobreajuste en los modelos. Use para esto la curva de aprendizaje. 

```{r}

```

### 13. Para el modelo elegido de regresi√≥n tunee los par√°metros y discuta si puede mejorar todav√≠a el modelo sin llegar a sobre ajustarlo.  

```{r}

```

### 14. Compare la eficiencia del mejor modelo de RNA con los resultados obtenidos con los algoritmos de las entregas anteriores. ¬øCu√°l es mejor para predecir? ¬øCu√°l se demor√≥ m√°s en procesar? 

```{r}

```

### 15. Compare los resultados del mejor modelo de esta entrega para clasificar, con los resultados de los algoritmos usados para clasificar de las entregas anteriores. 

```{r}

```

### 16. Compare los resultados del mejor modelo para predecir el precio de venta con los resultados de los algoritmos usados para el mismo prop√≥sito de las entregas anteriores. 

```{r}

```

### 17. Ahora que ha usado todos los modelos que hemos visto y aplicados al conjunto de datos llegue a conclusiones sobre cual es o cuales son los mejores modelos para clasificar dadas las caracter√≠sticas del conjunto de datos. ¬øCu√°l o cu√°les son los mejores para predecir el precio de las casas? Elabore una tabla de resumen con las m√©tricas de los modelos que est√° comparando. 

```{r}

```

### 18. Genere un informe total de la consultor√≠a donde incluya todas las entregas parciales. Debe incluir desde el an√°lisis exploratorio hasta esta entrega. Debe ser un informe general completamente coherente, sin subt√≠tulos relacionados con las instrucciones de las actividades de las entregas. Debe ser un informe formal, que pueda ser presentado a los directivos de la compa√±√≠a. 

```{r}

```

