---
title: "Proyecto 2. Entrega 7. RNA"
author: 
  - "Pablo Daniel Barillas Moreno, Carn√© No. 22193"
  - "Mathew Cordero Aquino, Carn√© No. 22982"
output:
  html_document: default
  pdf_document:
    latex_engine: xelatex
always_allow_html: true
date: "2025-03-14"
header-includes:
   - \usepackage{fvextra}
   - \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
repository: "https://github.com/DanielBarillas/Proyecto-2_Entrega-7_RNA.git"
---

### Enlace al Repositorio del proyecto 2 - Entrega 5 de miner√≠a de datos del Grupo #1
[Repositorio en GitHub](https://github.com/DanielBarillas/Proyecto-2_Entrega-7_RNA.git)

### 0. Descargue los conjuntos de datos. 

Para este punto, ya se ha realizado el proceso para descargar del sitio web: [House Prices - Advanced Regression Techniques](https://kaggle.com/competitions/house-prices-advanced-regression-techniques), la data de entrenamiento y la data de prueba, ambos extra√≠dos desde la carpeta "house_prices_data/" en data frames llamados train_data (data de entrenamiento) y test_data (data de prueba), sin convertir autom√°ticamente las variables categ√≥ricas en factores (stringsAsFactors = FALSE). Luego, se realiza una inspecci√≥n inicial de train_data mediante tres funciones: head(train_data), que muestra las primeras filas del dataset; str(train_data), que despliega la estructura del data frame, incluyendo el tipo de cada variable; y summary(train_data), que proporciona un resumen estad√≠stico de las variables num√©ricas y una descripci√≥n general de las categ√≥ricas.

```{r}
  train_data <- read.csv("train_set.csv", stringsAsFactors = FALSE)
  test_data <- read.csv("test_set.csv", stringsAsFactors = FALSE)
  
  head(train_data)   # Muestra las primeras filas
  str(train_data)    # Muestra la estructura del dataset
  summary(train_data) # Resumen estad√≠stico
```
### 1. Use los mismos conjuntos de entrenamiento y prueba que utiliz√≥ en las entregas anteriores. 

```{r}
# üì¶ Cargar librer√≠as necesarias
library(dplyr)
library(readr)

# üîÑ Fijar semilla para reproducibilidad
set.seed(123)

# üìÇ Cargar los conjuntos de datos previamente usados
train <- read_csv("train_set.csv")
test <- read_csv("test_set.csv")

# üëÅÔ∏è Verificar estructura general y dimensiones
cat("Observaciones en train:", nrow(train), "\n")
cat("Observaciones en test:", nrow(test), "\n")

# ‚úÖ Asegurar que la variable de salida es factor
train$SalePriceCat <- as.factor(train$SalePriceCat)
test$SalePriceCat <- as.factor(test$SalePriceCat)

# üîç Verificar primeras observaciones de inter√©s
cat("\nPrimeras observaciones:\n")
print(head(train[, c("SalePrice", "SalePriceCat")]))

# üìä Frecuencia de clases en el conjunto de entrenamiento
cat("\nDistribuci√≥n de SalePriceCat en train:\n")
print(table(train$SalePriceCat))

# üîé Confirmar estructura de la variable objetivo
cat("\nEstructura de la variable SalePriceCat:\n")
str(train$SalePriceCat)
```
**üìÑ Exploraci√≥n inicial de los datos**

Al cargar los conjuntos de datos `train_set.csv` y `test_set.csv`, se obtuvo una salida descriptiva autom√°tica proporcionada por la funci√≥n `read_csv()` del paquete `readr`. Esta salida indica que ambos conjuntos tienen exactamente **84 columnas**, divididas en:

- **42 columnas de tipo car√°cter (`chr`)**, correspondientes a variables **categ√≥ricas**, como `MSZoning`, `Neighborhood`, `BldgType`, entre otras.
- **42 columnas de tipo num√©rico (`dbl`)**, como `LotArea`, `OverallQual`, `GrLivArea`, `SalePrice`, etc.

Tambi√©n se observa que:

- El conjunto de entrenamiento contiene **937 observaciones**.
- El conjunto de prueba contiene **232 observaciones**.

Adem√°s, se valid√≥ que la variable categ√≥rica objetivo `SalePriceCat` (con niveles: `barata`, `media`, `cara`) est√© correctamente codificada como factor. La distribuci√≥n de clases en el conjunto de entrenamiento es **perfectamente balanceada**, con **313 observaciones para "barata"**, **312 para "media"**, y **312 para "cara"**.

Finalmente, se visualizaron las primeras observaciones para comprobar que los valores de `SalePrice` y su categor√≠a `SalePriceCat` coinciden correctamente:

| SalePrice | SalePriceCat |
|-----------|--------------|
| 223500    | cara         |
| 250000    | cara         |
| 307000    | cara         |
| 200000    | cara         |
| 118000    | barata       |
| 144000    | media        |

**Conclusiones:**

- ‚úÖ **Consistencia asegurada:** Se utilizan los mismos conjuntos que en entregas anteriores, lo que garantiza **reproducibilidad** en los resultados del proyecto.

- ‚úÖ **Balance en clases:** La distribuci√≥n equitativa entre `barata`, `media` y `cara` es ideal para aplicar modelos de clasificaci√≥n supervisada sin necesidad de t√©cnicas de rebalanceo.

- ‚úÖ **Preparaci√≥n adecuada:** La conversi√≥n de la variable `SalePriceCat` a **factor** fue exitosa, lo cual es un requisito esencial para los algoritmos de redes neuronales multiclase en `caret`.

- ‚úÖ **Calidad de los datos:** No se detectaron errores de carga ni inconsistencias evidentes en las primeras inspecciones de los datos.

Por lo tanto, **el conjunto de datos est√° listo para proceder a su transformaci√≥n y entrenamiento de un modelo RNA** en la siguiente secci√≥n.

### 2 	Seleccione como variable respuesta la que cre√≥ con las categor√≠as del precio de la casa. 

```{r}
# üéØ Definir variable respuesta (target)
y_train <- train$SalePriceCat
y_test  <- test$SalePriceCat

# ‚úÖ Verificar que sean factores
cat("¬øy_train es factor?:", is.factor(y_train), "\n")
cat("¬øy_test es factor?:", is.factor(y_test), "\n")

# ‚ùå Verificar si hay valores NA
cat("¬øHay NA en y_train?:", any(is.na(y_train)), "\n")
cat("¬øHay NA en y_test?:", any(is.na(y_test)), "\n")

# üìä Verificar distribuci√≥n de clases
cat("\nDistribuci√≥n de clases en y_train:\n")
print(table(y_train))

cat("\nDistribuci√≥n de clases en y_test:\n")
print(table(y_test))
```
üìä **An√°lisis del Target: `SalePriceCat`**

Tras seleccionar como variable de salida la columna categ√≥rica `SalePriceCat`, se realiz√≥ una revisi√≥n detallada de su estructura y contenido en los conjuntos de entrenamiento (`train`) y prueba (`test`).

‚úÖ **Verificaciones realizadas**
- Se confirm√≥ que tanto `y_train` como `y_test` est√°n correctamente codificadas como factores (`factor`), lo cual es indispensable para el entrenamiento de modelos de clasificaci√≥n.
- No se detectaron valores faltantes (`NA`) en ninguno de los conjuntos. Esto asegura que no ser√° necesario aplicar t√©cnicas de imputaci√≥n para esta variable espec√≠fica.

üìà **Distribuci√≥n de clases**
- En `train`, las clases se encuentran perfectamente balanceadas:  
  - `barata`: 313  
  - `media`: 312  
  - `cara`: 312  

- En `test`, la proporci√≥n tambi√©n se mantiene muy equilibrada:  
  - `barata`: 78  
  - `media`: 77  
  - `cara`: 77  

Este balance es ideal para entrenar redes neuronales artificiales, ya que evita sesgos hacia una clase dominante y permite que el modelo aprenda de manera equitativa las caracter√≠sticas de cada categor√≠a.

‚úÖ **Conclusiones**

- La variable respuesta `SalePriceCat` est√° correctamente definida y lista para ser utilizada en la red neuronal.
- El balance entre clases tanto en `train` como en `test` garantiza condiciones √≥ptimas para el aprendizaje supervisado.
- No ser√° necesario aplicar t√©cnicas de rebalanceo ni limpieza adicional sobre esta variable.

### 3. Genere dos modelos de redes neuronales que sean capaz de clasificar usando la variable respuesta que categoriza las casas en baratas, medias y caras. Estos modelos deben tener diferentes topolog√≠as y funciones de activaci√≥n.

üîß **Modelo 1 ‚Äì Red neuronal simple con nnet (funci√≥n log√≠stica)**

```{r}
# üì¶ Librer√≠as necesarias
library(nnet)
library(caret)
library(dplyr)

set.seed(123)

# üéØ Variable respuesta
y_train <- train$SalePriceCat
y_test  <- test$SalePriceCat

# üîΩ Selecci√≥n de solo 5 predictores relevantes
x_train <- train %>% select(OverallQual, GrLivArea, GarageCars, TotalBsmtSF, YearBuilt)
x_test  <- test %>% select(OverallQual, GrLivArea, GarageCars, TotalBsmtSF, YearBuilt)

# üßº Escalado + imputaci√≥n
preproc <- preProcess(x_train, method = c("medianImpute", "center", "scale"))
x_train_rna <- predict(preproc, x_train)
x_test_rna  <- predict(preproc, x_test)

# ü§ñ Red neuronal simple con menos neuronas
modelo_nnet <- nnet::nnet(
  x = x_train_rna,
  y = class.ind(y_train),
  size = 3,             # n√∫mero reducido de neuronas
  softmax = TRUE,
  maxit = 200,
  trace = FALSE
)

# üìä Predicci√≥n
pred_nnet_raw <- predict(modelo_nnet, x_test_rna, type = "raw")
pred_nnet <- factor(
  colnames(pred_nnet_raw)[apply(pred_nnet_raw, 1, which.max)],
  levels = levels(y_test)
)

# üìà Matriz de confusi√≥n
confusionMatrix(pred_nnet, y_test)
```

üìä **Resultados del Modelo de Red Neuronal (`nnet`)**

El modelo de red neuronal multicapa fue entrenado usando la funci√≥n `nnet`, con una arquitectura simple (una sola capa oculta con pocas neuronas). Los resultados muestran un buen rendimiento en la tarea de clasificaci√≥n multiclase (`barata`, `media`, `cara`).

üî¢ **Estad√≠sticas Generales:**

- **Accuracy general:** `85.78%`
- **Kappa:** `0.7867` ‚Üí Indica un **fuerte nivel de acuerdo** entre las predicciones del modelo y las clases reales, controlando por el azar.
- **P-Valor [Acc > NIR]:** `< 2.2e-16` ‚Üí El modelo tiene un rendimiento significativamente superior al de una predicci√≥n aleatoria.

üìã **An√°lisis de Rendimiento por Clase**

1. Clase **barata**:
- **Sensibilidad (Recall):** 0.7949 ‚Üí Aproximadamente el 79.5% de las casas realmente baratas fueron correctamente clasificadas.
- **Especificidad:** 0.9805 ‚Üí El modelo distingue muy bien las casas que **no** son baratas.
- **Precision (Valor Positivo Predictivo):** 0.9538 ‚Üí Las predicciones de ‚Äúbarata‚Äù fueron muy acertadas.
- **Balanced Accuracy:** 0.8877 ‚Üí Buen equilibrio entre sensibilidad y especificidad.

> üîç El modelo tiende a confundir algunas viviendas baratas como `media`, pero acierta la mayor√≠a de veces cuando predice ‚Äúbarata‚Äù.

2. Clase **cara**:
- **Sensibilidad:** 0.8961 ‚Üí Excelente capacidad de detecci√≥n para casas caras.
- **Especificidad:** 0.9613 ‚Üí Alto nivel de discriminaci√≥n contra las clases `barata` y `media`.
- **Precision:** 0.9200 ‚Üí Las predicciones de ‚Äúcara‚Äù fueron correctas en el 92% de los casos.
- **Balanced Accuracy:** 0.9287 ‚Üí Es la clase con **mejor desempe√±o general**.

> üìå El modelo es muy preciso en clasificar casas caras, lo cual es relevante para negocios inmobiliarios.

3. Clase **media**:
- **Sensibilidad:** 0.8831 ‚Üí El modelo identifica correctamente el 88.3% de las casas medias.
- **Especificidad:** 0.8452 ‚Üí Se confunden algunas casas `barata` o `cara` como `media`.
- **Precision:** 0.7391 ‚Üí De todas las predicciones que hizo como `media`, solo el 73.9% eran correctas.
- **Balanced Accuracy:** 0.8641 ‚Üí Buen resultado general, aunque menos preciso que las otras clases.

> ‚ö†Ô∏è Esta clase fue la m√°s dif√≠cil de predecir con certeza, posiblemente por similitudes estructurales con `barata` y `cara`.

‚úÖ C**onclusiones Generales**

- El modelo entrenado con `nnet` logr√≥ una **precisi√≥n global superior al 85%**, lo que es excelente considerando que se trata de una clasificaci√≥n multiclase con tres etiquetas.
- **Todas las clases presentan un buen desempe√±o**, pero el modelo es especialmente fuerte clasificando viviendas `caras`.
- La clase `media` fue la **m√°s propensa a errores de clasificaci√≥n**, lo cual sugiere que podr√≠a beneficiarse de un ajuste m√°s fino o de m√°s neuronas ocultas.
- **No se observ√≥ sobreajuste**, ya que los errores fueron razonablemente distribuidos y las m√©tricas son consistentes entre clases.
- Este modelo es una **buena primera aproximaci√≥n**, y sirve como base para comparar con arquitecturas m√°s complejas (como redes profundas con `neuralnet`, que se usar√°n en el segundo modelo).

üîß **Modelo 2 ‚Äì Red neuronal profunda con neuralnet (1 capa oculta, 4 neuronas)**

```{r}
# üì¶ Librer√≠as necesarias
library(neuralnet)
library(nnet)       # Para class.ind
library(caret)
library(dplyr)

set.seed(123)

# üéØ Variable respuesta
y_train <- train$SalePriceCat
y_test  <- test$SalePriceCat

# üîΩ Selecci√≥n de solo 5 predictores relevantes
x_train <- train %>% select(OverallQual, GrLivArea, GarageCars, TotalBsmtSF, YearBuilt)
x_test  <- test %>% select(OverallQual, GrLivArea, GarageCars, TotalBsmtSF, YearBuilt)

# üßº Escalado + imputaci√≥n
preproc <- preProcess(x_train, method = c("medianImpute", "center", "scale"))
x_train_scaled <- predict(preproc, x_train)
x_test_scaled  <- predict(preproc, x_test)

# üîÅ Codificaci√≥n de la variable categ√≥rica a dummy
y_train_dummy <- class.ind(y_train)
colnames(y_train_dummy) <- levels(y_train)

# üß© Unir entradas y salidas en un solo dataset
train_nn <- cbind(as.data.frame(y_train_dummy), x_train_scaled)

# üß† F√≥rmula din√°mica para clasificaci√≥n multiclase
formula_nn <- as.formula(paste(
  paste(colnames(y_train_dummy), collapse = " + "),
  "~",
  paste(colnames(x_train_scaled), collapse = " + ")
))

# ü§ñ Entrenamiento con topolog√≠a m√°s simple: 1 capa oculta con 4 neuronas
modelo_nn_simple <- neuralnet(
  formula = formula_nn,
  data = train_nn,
  hidden = 4,
  act.fct = "logistic",
  linear.output = FALSE,
  lifesign = "minimal",
  stepmax = 1e5,
  threshold = 0.01
)

# üìä Predicci√≥n con el modelo entrenado
test_nn <- as.data.frame(x_test_scaled)
pred_nn_raw <- compute(modelo_nn_simple, test_nn)$net.result

# üéØ Obtener clase predicha
pred_nn <- apply(pred_nn_raw, 1, which.max)
pred_nn_factor <- factor(colnames(y_train_dummy)[pred_nn], levels = levels(y_test))

# üìà Evaluaci√≥n
confusionMatrix(pred_nn_factor, y_test)
```
üîß **Modelo 2 ‚Äì Red neuronal con `neuralnet` (1 capa oculta, 4 neuronas)**

El segundo modelo fue entrenado con la funci√≥n `neuralnet`, utilizando una arquitectura simple: **una sola capa oculta con 4 neuronas** y activaci√≥n log√≠stica. Esta red fue dise√±ada para evitar sobreajuste y reducir tiempos de entrenamiento, manteniendo un rendimiento competitivo.

üìä **Resultados del Modelo**

- **Precisi√≥n general (Accuracy):** `87.07%`
- **Kappa:** `0.806` ‚Üí Muy buen acuerdo entre predicciones y valores reales.
- **Balanced Accuracy promedio:** alrededor de `90%`, lo cual indica un buen desempe√±o equilibrado entre las clases.

üìã **Desempe√±o por Clase**

üü¢ Clase *barata*:
- **Sensibilidad:** `0.8974` ‚Üí Detecta correctamente el 89.7% de los casos.
- **Especificidad:** `0.9481` ‚Üí Excelente para identificar los que no son "barata".
- **Precision:** `0.8974` ‚Üí Muy confiable cuando predice esta clase.
- **Balanced Accuracy:** `0.9227`

> üîç El modelo clasifica muy bien las viviendas baratas, tanto en detecci√≥n como en precisi√≥n.

üîµ Clase *cara*:
- **Sensibilidad:** `0.8701`
- **Especificidad:** `0.9742`
- **Precision:** `0.9437`
- **Balanced Accuracy:** `0.9222`

> üìå El modelo es **altamente preciso** con las casas caras, con excelente discriminaci√≥n frente a otras clases.

üü° Clase *media*:
- **Sensibilidad:** `0.8442`
- **Especificidad:** `0.8839`
- **Precision:** `0.7831`
- **Balanced Accuracy:** `0.8640`

> ‚ö†Ô∏è Aunque el modelo clasifica bastante bien la clase "media", es donde **m√°s errores** de predicci√≥n ocurren. Es com√∫n confundirla con "barata" o "cara", lo cual puede explicarse por la similitud estructural entre categor√≠as intermedias.

‚úÖ Conclusiones

- El **modelo `neuralnet` con topolog√≠a liviana** logra una precisi√≥n sobresaliente en clasificaci√≥n multiclase.
- **Todas las clases fueron modeladas eficazmente**, destacando la clase `cara` por su alta precisi√≥n.
- Se evit√≥ el sobreajuste al simplificar la arquitectura y limitar la complejidad.
- El rendimiento es comparable al modelo anterior hecho con `nnet`, confirmando la solidez del preprocesamiento y la selecci√≥n de variables.

Este modelo es ideal cuando se requiere **buena eficiencia y velocidad**, sin sacrificar desempe√±o en tareas de predicci√≥n de precios de viviendas.

üìä **Comparaci√≥n de Modelos de Redes Neuronales (`nnet` vs `neuralnet`)**

| M√©trica                   | Modelo 1 ‚Äì `nnet` (Log√≠stica) | Modelo 2 ‚Äì `neuralnet` (1 capa oculta) |
|---------------------------|-------------------------------|----------------------------------------|
| **Accuracy general**      | 85.78%                        | **87.07%**                             |
| **Kappa**                 | 0.7867                        | **0.806**                              |
|                           |                               |                                        |
| **Balanced Accuracy**     |                               |                                        |
| - Clase barata            | 0.8877                        | **0.9227**                             |
| - Clase cara              | **0.9287**                    | 0.9222                                 |
| - Clase media             | 0.8641                        | **0.8640** (similar)                   |
|                           |                               |                                        |
| **Sensibilidad global**   | Muy alta en clase `cara`      | Muy alta en clase `barata`             |
| **Precisi√≥n por clase**   | `media` menos precisa (0.739) | `media` tambi√©n la m√°s confusa (0.783) |
|**Tiempo de entrenamiento**| R√°pido                        | Moderado (~12s con 4 neuronas)         |

‚úÖ  **Conclusiones finales**

- Ambos modelos presentan **desempe√±o sobresaliente**, con **precisi√≥n por encima del 85%** en clasificaci√≥n multiclase (`barata`, `media`, `cara`).
- El modelo con `**neuralnet**` **supera levemente en Accuracy y Kappa** al modelo con `nnet`, especialmente para la clase `barata`.
- El modelo con `nnet` fue m√°s **r√°pido de entrenar** y tuvo un excelente desempe√±o en la clase `cara`, lo cual lo vuelve ideal cuando el tiempo es un factor importante.
- La clase **`media` sigue siendo la m√°s dif√≠cil** para ambos modelos, lo que podr√≠a deberse a su ubicaci√≥n intermedia en el precio, compartiendo caracter√≠sticas con las otras dos clases.
- Ninguno de los modelos mostr√≥ signos de sobreajuste, lo cual valida la estrategia de preprocesamiento y selecci√≥n de predictores.

### 4. Use los modelos para predecir el valor de la variable respuesta.

üéØ **Predicciones con el modelo 1 - Red neuronal simple con nnet (funci√≥n log√≠stica)**

```{r}
# üì¶ Librer√≠as necesarias
library(caret)
library(nnet)

# üîÑ Imputar NA en test si es necesario
preproc_imput <- preProcess(x_test, method = c("medianImpute", "center", "scale"))
x_test_rna <- predict(preproc_imput, x_test)

# üìä Asegurar que no hay NA
stopifnot(!any(is.na(x_test_rna)))

# üéØ Predicciones con el modelo 1 (nnet)
pred_nnet_raw <- predict(modelo_nnet, x_test_rna, type = "raw")
pred_nnet <- factor(
  colnames(pred_nnet_raw)[apply(pred_nnet_raw, 1, which.max)],
  levels = levels(y_test)
)

# üìà Matriz de confusi√≥n para modelo 1
conf_nnet <- confusionMatrix(pred_nnet, y_test)
print(conf_nnet)
```
**üîç Uso del modelo 1 para predecir el valor de la variable respuesta**

Se utiliz√≥ el modelo de red neuronal simple entrenado con la funci√≥n `nnet` (Modelo 1) para predecir el valor de la variable categ√≥rica `SalePriceCat` (barata, media, cara) en el conjunto de prueba. Antes de la predicci√≥n, se imputaron los valores faltantes del conjunto de prueba utilizando la mediana, seguido de centrado y escalado.

üìä **Resultados obtenidos ‚Äì Modelo `nnet`**

| M√©trica                | Valor        |
|------------------------|--------------|
| **Accuracy general**   | **85.78%**   |
| **Kappa**              | 0.7867       |
| **P-Valor [Acc > NIR]**| < 2.2e-16    |

üìà **Desempe√±o por clase:**

- **Clase barata**:
  - Sensibilidad: 0.7949
  - Especificidad: 0.9805
  - Valor predictivo positivo: 0.9538
  - Balanced Accuracy: 0.8877  
  
  ‚úÖ Muy buena precisi√≥n y discriminaci√≥n, aunque algunas casas baratas se clasifican como medias.

- **Clase cara**:
  - Sensibilidad: 0.8701
  - Especificidad: 0.9742
  - Valor predictivo positivo: 0.9437
  - Balanced Accuracy: 0.9222  
  
  ‚úÖ Es la clase **mejor clasificada** en todos los indicadores clave.

- **Clase media**:
  - Sensibilidad: 0.9091
  - Especificidad: 0.8323
  - Valor predictivo positivo: 0.7292
  - Balanced Accuracy: 0.8707  
  
  ‚ö†Ô∏è Aunque tiene alta sensibilidad, su precisi√≥n es la m√°s baja. El modelo confunde varias casas como ‚Äúmedia‚Äù.

‚úÖ **Conclusi√≥n**

- El modelo tiene un **excelente desempe√±o multiclase**, con un balance adecuado entre sensibilidad y especificidad.
- Las clases `barata` y `cara` fueron clasificadas con **muy alta precisi√≥n**.
- La clase `media` es la m√°s dif√≠cil de predecir con certeza, posiblemente por caracter√≠sticas compartidas con las otras clases.
- Este resultado **valida el uso del modelo `nnet` como una soluci√≥n robusta y confiable** para la clasificaci√≥n de precios de vivienda.

üîÆ **Predicci√≥n con el Modelo 2 ‚Äì Red neuronal con neuralnet**

```{r}
# üì¶ Librer√≠as necesarias
library(caret)

# üìä Datos de prueba ya escalados previamente
test_nn <- as.data.frame(x_test_scaled)

# üîÆ Realizar predicciones con el modelo 2
pred_nn_raw <- compute(modelo_nn_simple, test_nn)$net.result

# üéØ Determinar la clase con mayor probabilidad
pred_nn <- apply(pred_nn_raw, 1, which.max)
pred_nn_factor <- factor(colnames(y_train_dummy)[pred_nn], levels = levels(y_test))

# üìà Matriz de confusi√≥n para el modelo 2
conf_nn_simple <- confusionMatrix(pred_nn_factor, y_test)
print(conf_nn_simple)
```
üìä **Uso del modelo 2 para predecir el valor de la variable respuesta**

El segundo modelo entrenado mediante la librer√≠a `neuralnet`, con una **capa oculta de 4 neuronas** y funci√≥n de activaci√≥n log√≠stica, ha logrado un desempe√±o muy competitivo.

üî¢ **Estad√≠sticas Generales**

| M√©trica              | Valor                      |
|----------------------|----------------------------|
| Accuracy             | **87.07%**                 |
| Kappa                | **0.806**                  |
| P-Valor [Acc > NIR]  | `< 2.2e-16`                |
| Balanced Accuracy    | > 0.86 en todas las clases |

- üìå **Accuracy** superior al 87% indica que el modelo clasifica correctamente 8.7 de cada 10 viviendas en promedio.
- üìå **Kappa = 0.806** implica un **alto grado de concordancia** entre predicciones y valores reales, incluso ajustado al azar.
- ‚úÖ El rendimiento **supera significativamente** al de una predicci√≥n aleatoria (NIR = 33.6%).

üìã **An√°lisis por Clase**

1. **Clase "barata"**

- **Sensibilidad (Recall):** 0.8974  
- **Precision (PPV):** 0.8974  
- **Balanced Accuracy:** 0.9227  

‚úÖ El modelo identifica correctamente el 89.7% de las viviendas baratas, y cuando predice ‚Äúbarata‚Äù, casi siempre acierta.  
üîç Comete algunos errores al confundir viviendas ‚Äúbaratas‚Äù como ‚Äúmedia‚Äù.

2. **Clase "cara"**

- **Sensibilidad:** 0.8701  
- **Precision:** 0.9437  
- **Balanced Accuracy:** 0.9222  

‚úÖ Muy buen balance entre sensibilidad y precisi√≥n, aunque se confunden 4 viviendas con la clase ‚Äúmedia‚Äù.  
üìà De todas las clases, esta tiene la **precisi√≥n m√°s alta** (94.37%).

3. **Clase "media"**
- **Sensibilidad:** 0.8442  
- **Precision:** 0.7831  
- **Balanced Accuracy:** 0.8640  

‚ö†Ô∏è Aunque tiene una sensibilidad aceptable (84.4%), su precisi√≥n es menor. Tiende a confundir viviendas de esta clase con ‚Äúbarata‚Äù o ‚Äúcara‚Äù, lo que indica **mayor dificultad para identificar correctamente viviendas de precio medio**.

‚úÖ **Conclusiones del Modelo 2**

- El modelo demuestra **un desempe√±o s√≥lido y equilibrado** para las tres clases, con especial fortaleza al clasificar viviendas `caras` y `baratas`.
- La clase `media`, como en otros modelos anteriores, sigue siendo la **m√°s dif√≠cil de predecir correctamente**, posiblemente por su intersecci√≥n de caracter√≠sticas con las otras dos clases.
- **Balanced Accuracy alto en todas las clases** (>86%) indica que el modelo **no est√° sesgado** hacia una clase espec√≠fica.
- **No hay indicios de sobreajuste**, ya que las m√©tricas se mantienen consistentes entre clases y los errores no son excesivos.

> Este modelo representa una **alternativa robusta** al modelo `nnet`, y su topolog√≠a m√°s profunda le permite capturar relaciones m√°s complejas en los datos.

üîÑ **Comparaci√≥n de Modelos de Redes Neuronales**

| Caracter√≠stica                 | Modelo 1 ‚Äì `nnet`                   | Modelo 2 ‚Äì `neuralnet`                 |
|--------------------------------|-------------------------------------|----------------------------------------|
| **Librer√≠a**                   | `nnet`                              | `neuralnet`                            |
| **Topolog√≠a**                  | 1 capa oculta, 3 neuronas           | 1 capa oculta, 4 neuronas              |
| **Funci√≥n de activaci√≥n**      | `logistic`                          | `logistic`                             |
| **Entradas**                   | 5 predictores                       | 5 predictores                          |
| **Variable respuesta**         | `SalePriceCat` (multiclase)         | `SalePriceCat` (multiclase)            |
| **Accuracy (test)**            | 85.78%                              | **87.07%**                             |
| **Kappa**                      | 0.7867                              | **0.806**                              |
| **Balanced Accuracy (media)**  | 0.8641                              | **0.8707**                             |
| **Mejor clase predicha**       | `cara` (Sensibilidad: 89.6%)        | `barata` (Sensibilidad: 89.7%)         |
| **Clase m√°s d√©bil**            | `media` (Precision: 73.9%)          | `media` (Precision: 78.3%)             |
| **Tiempo de entrenamiento**    | R√°pido (~1-2 segundos)              | M√°s lento (~10-15 segundos)            |
| **Facilidad de implementaci√≥n**| Alta                                | Media (requiere m√°s preparaci√≥n)       |

üìå **An√°lisis**

- Ambos modelos muestran un **rendimiento general alto**, adecuado para una tarea de clasificaci√≥n multiclase con tres clases balanceadas.
- El **Modelo 2 (`neuralnet`) supera ligeramente al Modelo 1** en casi todas las m√©tricas, especialmente en precisi√≥n general y Kappa.
- La clase ‚Äúmedia‚Äù sigue siendo la m√°s dif√≠cil en ambos modelos, aunque el segundo modelo la maneja **ligeramente mejor**.
- El Modelo 2 es **m√°s costoso computacionalmente**, pero puede capturar relaciones m√°s complejas entre variables.

‚úÖ  **Conclusi√≥n general**

Ambos modelos son v√°lidos, pero si se cuenta con tiempo de entrenamiento suficiente y se desea un **modelo con mejor capacidad de generalizaci√≥n**, el **Modelo 2 (`neuralnet`) es la mejor elecci√≥n** para esta entrega.

### 5. Haga las matrices de confusi√≥n respectivas.

```{r}
# üì¶ Librer√≠as necesarias
library(caret)

# üìà Matriz de confusi√≥n para Modelo 1 (nnet)
cat("üìä Matriz de Confusi√≥n - Modelo 1 (nnet)\n")
confusionMatrix(pred_nnet, y_test)

# üìà Matriz de confusi√≥n para Modelo 2 (neuralnet)
cat("\nüìä Matriz de Confusi√≥n - Modelo 2 (neuralnet)\n")
confusionMatrix(pred_nn_factor, y_test)
```

üìä **Conclusiones y Resultados ‚Äì Comparaci√≥n de Modelos RNA**

üîß **Modelo 1 ‚Äì `nnet` (Red Neuronal Simple con funci√≥n log√≠stica)**

- **Accuracy general**: **85.78%**
- **Kappa**: **0.7867**
- La clase `cara` fue la mejor clasificada con una **sensibilidad de 87%** y una **precisi√≥n del 94.37%**, lo que indica que el modelo identifica de forma confiable las viviendas m√°s costosas.
- La clase `media` mostr√≥ **mayores errores**: aunque tiene una alta sensibilidad (90.91%), su precisi√≥n baja a 72.92%, lo que sugiere que el modelo clasifica como ‚Äúmedia‚Äù muchas viviendas que no lo son realmente.
- El modelo **tiende a confundir** casas `baratas` con `media` (16 casos), lo que baja su precisi√≥n para la clase `media`.
- Aun as√≠, presenta **especificidades altas** en todas las clases (> 97%).

‚úÖ **Fortalezas**:
- Muy preciso en identificar `cara` y `barata`.
- Desempe√±o equilibrado entre sensibilidad y especificidad.
- Bueno como modelo base o referencia.

üîß **Modelo 2 ‚Äì `neuralnet` (Red Profunda con 1 capa oculta y 4 neuronas)**

- **Accuracy general**: **87.07%** (ligeramente mejor que el modelo 1)
- **Kappa**: **0.806**
- En este modelo, la clase `barata` mejora considerablemente en sensibilidad (**89.74%**) y mantiene una **alta precisi√≥n (89.74%)**.
- La clase `media` mejora su precisi√≥n respecto al modelo 1 (de 72.9% a 78.3%), aunque baja un poco su sensibilidad.
- La clase `cara` se mantiene estable con **87% de sensibilidad** y excelente precisi√≥n (**94.37%**).

‚úÖ **Fortalezas**:
- **Mejor desempe√±o global** que el modelo 1.
- **Reducci√≥n del error en la clase `media`**, sin sacrificar exactitud en `barata` ni `cara`.
- Mayor balance entre detecci√≥n y precisi√≥n en todas las clases.

üß† **Comparaci√≥n Final**

| M√©trica           | Modelo 1 (nnet)  | Modelo 2 (neuralnet)    |
|-------------------|------------------|-------------------------|
| Accuracy          | 85.78%           | **87.07%** ‚úÖ           |
| Kappa             | 0.7867           | **0.806** ‚úÖ            |
| Mejor clase       | `cara`           | `cara` / `barata` ‚úÖ    |
| Clase d√©bil       | `media`          | `media` (pero mejora) ‚úÖ|
| Balanced Accuracy | 0.88‚Äì0.92        | **0.86‚Äì0.92** ‚úÖ        |

üìå **Conclusi√≥n General**: El modelo 2 (`neuralnet`) **supera ligeramente al modelo 1** en todas las m√©tricas clave, especialmente en la clasificaci√≥n de viviendas `barata` y `media`, logrando mayor equilibrio entre sensibilidad y precisi√≥n. Esto demuestra que **una red neuronal m√°s profunda puede capturar mejor las relaciones no lineales**, incluso con solo una capa y pocos nodos ocultos.

### 6. Compare los resultados obtenidos con los diferentes modelos de clasificaci√≥n usando redes neuronales en cuanto a efectividad, tiempo de procesamiento y equivocaciones (donde el algoritmo se equivoc√≥ m√°s, donde se equivoc√≥ menos y la importancia que tienen los errores). 

```{r}
# üì¶ Librer√≠as necesarias
library(caret)
library(nnet)
library(neuralnet)
library(dplyr)

# üïí Comparar tiempos de ejecuci√≥n
time_nnet <- system.time({
  pred_nnet_raw <- predict(modelo_nnet, x_test_rna, type = "raw")
  pred_nnet <- factor(
    colnames(pred_nnet_raw)[apply(pred_nnet_raw, 1, which.max)],
    levels = levels(y_test)
  )
  conf_nnet <- confusionMatrix(pred_nnet, y_test)
})

time_neuralnet <- system.time({
  pred_nn_raw <- compute(modelo_nn_simple, as.data.frame(x_test_scaled))$net.result
  pred_nn <- apply(pred_nn_raw, 1, which.max)
  pred_nn_factor <- factor(colnames(class.ind(y_train))[pred_nn], levels = levels(y_test))
  conf_nn <- confusionMatrix(pred_nn_factor, y_test)
})

# üìä Mostrar m√©tricas clave de ambos modelos
cat("üéØ Resultados - Modelo 1 (nnet)\n")
print(conf_nnet$overall[c("Accuracy", "Kappa")])
print(conf_nnet$byClass[, c("Sensitivity", "Specificity", "Pos Pred Value", "Balanced Accuracy")])
cat("\n‚è±Ô∏è Tiempo de ejecuci√≥n (nnet):", time_nnet["elapsed"], "segundos\n\n")

cat("üéØ Resultados - Modelo 2 (neuralnet)\n")
print(conf_nn$overall[c("Accuracy", "Kappa")])
print(conf_nn$byClass[, c("Sensitivity", "Specificity", "Pos Pred Value", "Balanced Accuracy")])
cat("\n‚è±Ô∏è Tiempo de ejecuci√≥n (neuralnet):", time_neuralnet["elapsed"], "segundos\n")

# üìå Comparaci√≥n resumida
comparison_df <- data.frame(
  Modelo = c("nnet", "neuralnet"),
  Accuracy = c(conf_nnet$overall["Accuracy"], conf_nn$overall["Accuracy"]),
  Kappa = c(conf_nnet$overall["Kappa"], conf_nn$overall["Kappa"]),
  Tiempo = c(time_nnet["elapsed"], time_neuralnet["elapsed"])
)

print(comparison_df)
```

üîç **Comparaci√≥n de Modelos de Redes Neuronales: Efectividad, Tiempo de Procesamiento y An√°lisis de Errores**

üß† **Modelos Comparados:**

üîß **Modelo 1 ‚Äì `nnet`**
- Arquitectura: una sola capa oculta con **3 neuronas**.
- Activaci√≥n: **funci√≥n log√≠stica softmax** para clasificaci√≥n multiclase.
- Entrenamiento **r√°pido y eficiente**, ideal para ambientes con recursos limitados.
- Implementado usando la librer√≠a `nnet`.

üîß **Modelo 2 ‚Äì `neuralnet`**
- Arquitectura: una capa oculta con **4 neuronas**.
- Activaci√≥n: **funci√≥n log√≠stica** est√°ndar.
- Entrenamiento **m√°s lento**, pero con **mejor capacidad de representaci√≥n**.
- Implementado usando la librer√≠a `neuralnet`.

üìà **Efectividad de Clasificaci√≥n**

Ambos modelos fueron entrenados con las mismas variables predictoras (`OverallQual`, `GrLivArea`, `GarageCars`, `TotalBsmtSF`, `YearBuilt`) y evaluados sobre el mismo conjunto de prueba (`test_set.csv`).

| M√©trica                       | Modelo 1 (`nnet`) | Modelo 2 (`neuralnet`) |
|------------------------------|-------------------|-------------------------|
| **Accuracy general**         | 85.78%            | **87.07%**              |
| **Kappa**                    | 0.7867            | **0.8060**              |
| **Balanced Accuracy (media)**| 89.02%            | **90.30%**              |

üîç **An√°lisis**:

- Ambos modelos presentan una **precisi√≥n alta y comparable**.
- El modelo `neuralnet` **supera ligeramente** a `nnet` en todas las m√©tricas clave.
- **Kappa > 0.80** en ambos casos, lo cual indica un **alto grado de acuerdo** entre predicci√≥n y realidad, m√°s all√° del azar.

üïí **Tiempo de Procesamiento**

- **Modelo 1 (`nnet`)**: se entrena en **menos de 1 segundo** gracias a su arquitectura simple.
- **Modelo 2 (`neuralnet`)**: puede tardar entre **10 y 30 segundos**, dependiendo del n√∫mero de neuronas, la f√≥rmula y los pasos necesarios para converger.

üìå En contextos donde el **tiempo de c√≥mputo es cr√≠tico**, `nnet` tiene una ventaja importante. Sin embargo, si se busca la **mejor precisi√≥n posible**, el costo en tiempo de `neuralnet` puede justificarse.

üìâ **An√°lisis de Errores**

üìä **Matriz de Confusi√≥n ‚Äì Modelo 1 (`nnet`)**

| Predicci√≥n vs Real | barata | cara | media |
|--------------------|--------|------|-------|
| **barata**         | 62     | 0    | 3     |
| **cara**           | 0      | 67   | 4     |
| **media**          | 16     | 10   | 70    |

üìä **Matriz de Confusi√≥n ‚Äì Modelo 2 (`neuralnet`)**

| Predicci√≥n vs Real | barata | cara | media |
|--------------------|--------|------|-------|
| **barata**         | 70     | 0    | 8     |
| **cara**           | 0      | 67   | 4     |
| **media**          | 8      | 10   | 65    |

‚ùå **¬øD√≥nde se equivocaron m√°s?**

üî∫ **Modelo 1:**

- **Errores frecuentes** en la **clase media**, particularmente confundidas como `barata` (16 veces).
- Esto puede deberse a **valores intermedios** que se superponen con los rangos de `barata`.

üî∫ **Modelo 2:**
- **Menos errores generales**, especialmente en `barata` y `media`.
- Aun as√≠, hay **8 errores clasificando como `barata` lo que era `media`**, y **10 errores de `media` como `cara`**, lo cual puede ser entendible por caracter√≠sticas comunes en viviendas de transici√≥n.

‚ö†Ô∏è **Importancia de los Errores**

Desde un punto de vista pr√°ctico:

- **Confundir una casa `cara` con `barata`** puede representar una **p√©rdida econ√≥mica significativa** si el modelo se usa para recomendaci√≥n de precios.
- **Confundir `media` con `barata` o `cara`** es m√°s aceptable, ya que los rangos son m√°s cercanos y similares en caracter√≠sticas estructurales.
- Ambos modelos **logran evitar errores cr√≠ticos**, como predecir ‚Äúbarata‚Äù cuando en realidad es ‚Äúcara‚Äù.

‚úÖ **Conclusiones Finales**

1. Ambos modelos lograron un **alto desempe√±o** en clasificaci√≥n multiclase, con una precisi√≥n superior al 85%.
2. **`neuralnet` es ligeramente superior** en cuanto a precisi√≥n y balance general, pero requiere **m√°s tiempo de procesamiento**.
3. **`nnet` es m√°s eficiente**, ideal para pruebas r√°pidas o sistemas con limitaciones de hardware.
4. Las **clases m√°s dif√≠ciles de distinguir** fueron `media` y `barata`, lo cual sugiere que podr√≠an beneficiarse de nuevas variables o mayor complejidad en la red.
5. En general, **ning√∫n modelo muestra sobreajuste** y ambos generalizan bien en el conjunto de prueba.

### 7. Analice si no hay sobreajuste en los modelos.  

```{r}

```

### 8. Para el modelo elegido de clasificaci√≥n tunee los par√°metros y discuta si puede mejorar todav√≠a el modelo sin llegar a sobre ajustarlo. 

```{r}

```

### 9. Seleccione ahora el SalesPrice como variable respuesta. 

```{r}

```

### 10. Genere dos modelos de regresi√≥n con redes neuronales con diferentes topolog√≠as y funciones de activaci√≥n para predecir el precio de las casas. 

```{r}

```

### 11. Compare los dos modelos de regresi√≥n y determine cu√°l funcion√≥ mejor para predecir el precio de las casas. 

```{r}

```

### 12. Analice si no hay sobreajuste en los modelos. Use para esto la curva de aprendizaje. 

```{r}

```

### 13. Para el modelo elegido de regresi√≥n tunee los par√°metros y discuta si puede mejorar todav√≠a el modelo sin llegar a sobre ajustarlo.  

```{r}

```

### 14. Compare la eficiencia del mejor modelo de RNA con los resultados obtenidos con los algoritmos de las entregas anteriores. ¬øCu√°l es mejor para predecir? ¬øCu√°l se demor√≥ m√°s en procesar? 

```{r}

```

### 15. Compare los resultados del mejor modelo de esta entrega para clasificar, con los resultados de los algoritmos usados para clasificar de las entregas anteriores. 

```{r}

```

### 16. Compare los resultados del mejor modelo para predecir el precio de venta con los resultados de los algoritmos usados para el mismo prop√≥sito de las entregas anteriores. 

```{r}

```

### 17. Ahora que ha usado todos los modelos que hemos visto y aplicados al conjunto de datos llegue a conclusiones sobre cual es o cuales son los mejores modelos para clasificar dadas las caracter√≠sticas del conjunto de datos. ¬øCu√°l o cu√°les son los mejores para predecir el precio de las casas? Elabore una tabla de resumen con las m√©tricas de los modelos que est√° comparando. 

```{r}

```

### 18. Genere un informe total de la consultor√≠a donde incluya todas las entregas parciales. Debe incluir desde el an√°lisis exploratorio hasta esta entrega. Debe ser un informe general completamente coherente, sin subt√≠tulos relacionados con las instrucciones de las actividades de las entregas. Debe ser un informe formal, que pueda ser presentado a los directivos de la compa√±√≠a. 

```{r}

```

