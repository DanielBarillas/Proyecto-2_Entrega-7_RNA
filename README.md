# ğŸ“Š Entrega 7: Redes Neuronales Artificiales (RNA)

---

# ğŸ§  Proyecto de ClasificaciÃ³n y RegresiÃ³n con Redes Neuronales

---

## ğŸ« Universidad del Valle de Guatemala - Campus Central  
**Facultad:** IngenierÃ­a  
**Departamento:** Ciencias de la ComputaciÃ³n  
**Curso:** MinerÃ­a de Datos (CC3074) - SecciÃ³n 10  
**Semestre:** I â€“ 2025  
**Proyecto:** Proyecto #2  
**Entrega:** Entrega 7 â€“ Redes Neuronales Artificiales  

---

## ğŸ‘¥ Integrantes del Grupo #1  
- **Pablo Daniel Barillas Moreno** - *CarnÃ© No. 22193*  
- **Mathew Cordero Aquino** - *CarnÃ© No. 22982*  

---

## ğŸ“Œ DescripciÃ³n del Proyecto  

En esta entrega se desarrollaron dos modelos de **Redes Neuronales Artificiales** con el objetivo de clasificar viviendas como **baratas**, **medias** o **caras**, y tambiÃ©n se abordÃ³ el problema de regresiÃ³n para predecir el valor real de venta (`SalePrice`) de las viviendas. Se utilizaron los conjuntos `train_set.csv` y `test_set.csv` definidos previamente.

---

## ğŸ” Actividades Realizadas  

### Serie 1: ReutilizaciÃ³n de Conjuntos  
- Se cargaron los archivos `train_set.csv` (937 observaciones) y `test_set.csv` (232 observaciones).
- Se validÃ³ que `SalePriceCat` estuviera correctamente categorizada y balanceada (aprox. 1/3 por clase).

### Serie 2: SelecciÃ³n de Variable Respuesta  
- Se seleccionÃ³ `SalePriceCat` como variable de salida para clasificaciÃ³n.
- Se confirmÃ³ que no existieran valores nulos y que las etiquetas fueran factores correctamente definidos.

### Serie 3: Entrenamiento de Modelos de RNA  
- **Modelo 1:** Red neuronal simple con `nnet`, 5 predictores y 3 neuronas ocultas.
- **Modelo 2:** Red neuronal con `neuralnet`, misma entrada pero con 1 capa oculta de 4 neuronas.
- Se aplicÃ³ centrado, escalado e imputaciÃ³n a los datos.
- Ambos modelos se entrenaron correctamente y mostraron convergencia sin errores.

### Serie 4: PredicciÃ³n y EvaluaciÃ³n  
- Ambos modelos realizaron predicciones sobre el conjunto de prueba.
- Se generaron **matrices de confusiÃ³n** para comparar sus desempeÃ±os.
- Resultados:
  - **Modelo 1 (`nnet`)**: Accuracy = 85.78%, Kappa = 0.7867
  - **Modelo 2 (`neuralnet`)**: Accuracy = 87.07%, Kappa = 0.806

### Serie 5: EvaluaciÃ³n de Modelos  
- Se analizaron mÃ©tricas por clase: sensibilidad, especificidad, precisiÃ³n y balanced accuracy.
- Se observÃ³ que la clase **media** fue la mÃ¡s difÃ­cil de predecir.
- Se generaron grÃ¡ficas de matrices de confusiÃ³n para comparar visualmente errores y aciertos.

### Serie 6: ComparaciÃ³n de Modelos  
- Se comparÃ³ efectividad, tiempo de entrenamiento y errores por clase.
- Ambos modelos fueron similares, pero `neuralnet` mostrÃ³ **ligera ventaja en precisiÃ³n general**.
- El modelo `nnet` fue mÃ¡s rÃ¡pido en tiempo de ejecuciÃ³n.

### Serie 7: AnÃ¡lisis de Overfitting  
- No se detectÃ³ sobreajuste en ninguno de los dos modelos.
- Se observÃ³ consistencia entre mÃ©tricas de validaciÃ³n cruzada y prueba.
- Las curvas de aprendizaje fueron estables y convergentes.

### Serie 8: Tuning de ParÃ¡metros  
- Se utilizÃ³ `caret::train` con validaciÃ³n cruzada 10-fold para tunear el modelo `nnet`.
- Mejores resultados con `size = 3` y `decay = 0.1`.
- No se observÃ³ sobreajuste posterior al tuning; el modelo se mantuvo robusto.

### Serie 9: Cambio a RegresiÃ³n (SalePrice)  
- Se reemplazÃ³ la variable objetivo por `SalePrice` para abordar el problema como regresiÃ³n.
- Se aplicÃ³ el mismo preprocesamiento.
- Se confirmÃ³ el rango de precios (`35,311` a `745,000`) y consistencia en el conjunto.

### Serie 10: Modelos de RegresiÃ³n con Redes Neuronales

* Se entrenaron **dos modelos de regresiÃ³n** con redes neuronales para predecir el precio `SalePrice`:

  * Modelo 1: Red simple con `neuralnet` (1 capa, 3 neuronas).
  * Modelo 2: Red profunda con `neuralnet` (2 capas: 4 y 2 neuronas).
* Ambos modelos utilizaron los mismos 5 predictores (`OverallQual`, `GrLivArea`, `GarageCars`, `TotalBsmtSF`, `YearBuilt`) con preprocesamiento previo.
* La evaluaciÃ³n se hizo con mÃ©tricas de regresiÃ³n como **RMSE**, **MAE**, y **RÂ²**.

### Serie 11: ComparaciÃ³n entre los Modelos de RegresiÃ³n

* Se compararon los modelos por desempeÃ±o en el conjunto de prueba:

  * Modelo 1: RMSE â‰ˆ 36,000; RÂ² â‰ˆ 0.78
  * Modelo 2: RMSE â‰ˆ 32,500; RÂ² â‰ˆ 0.83
* El **modelo 2 fue superior** en precisiÃ³n sin evidencia clara de sobreajuste.

### Serie 12: AnÃ¡lisis de Sobreajuste en RegresiÃ³n

* Se usaron **curvas de aprendizaje** para visualizar el error de entrenamiento vs prueba.
* En ambos modelos, las curvas convergieron sin grandes brechas, **descartando sobreajuste**.
* Se observÃ³ estabilidad en el error conforme aumentaban los datos de entrenamiento.

### Serie 13: Tuneo de ParÃ¡metros del Mejor Modelo

* Se ajustaron hiperparÃ¡metros (`hidden`, `threshold`, `stepmax`, `act.fct`) del modelo 2.
* La mejor configuraciÃ³n fue con:

  * Capas ocultas: 4 y 2 neuronas
  * ActivaciÃ³n: `logistic`
  * Threshold: 0.01
* **El tuning mejorÃ³ levemente el RMSE y RÂ²**, sin provocar sobreajuste.

### Serie 14: ComparaciÃ³n con Modelos de Entregas Anteriores (RegresiÃ³n)

* Se comparÃ³ el mejor modelo RNA con:

  * RegresiÃ³n Lineal: RÂ² â‰ˆ 0.89, RMSE â‰ˆ 28,000
  * Random Forest: RÂ² â‰ˆ 0.98, RMSE â‰ˆ 15,000
  * SVM: RÂ² â‰ˆ 0.87, RMSE â‰ˆ 33,000
* RNA tuvo **buen desempeÃ±o**, pero fue **superado por Random Forest y RegresiÃ³n Lineal** en eficiencia y precisiÃ³n.

### Serie 15: ComparaciÃ³n de Modelos de ClasificaciÃ³n

* Comparando el modelo RNA (clasificaciÃ³n) con entregas anteriores:

  * **SVM radial** y **RNA** obtuvieron los mejores `Kappa` (> 0.80).
  * RNA fue **mÃ¡s costoso computacionalmente**.
  * RNA tuvo ventaja en sensibilidad para la clase â€œcaraâ€, pero menor precisiÃ³n en â€œmediaâ€.

### Serie 16: ComparaciÃ³n de Modelos para Predecir Precio

* En regresiÃ³n pura, **Random Forest y RegresiÃ³n Lineal** dominaron por su precisiÃ³n y rapidez.
* RNA fue una buena alternativa, **aunque mÃ¡s costosa y menos estable**.
* A pesar de su flexibilidad, **no fue el modelo mÃ¡s efectivo** en este caso.

### Serie 17: Conclusiones Globales de Modelos Usados

| Tipo de Modelo | Algoritmo         | Accuracy/RÂ² | Kappa/MAE | Ventaja principal           |
| -------------- | ----------------- | ----------- | --------- | --------------------------- |
| ClasificaciÃ³n  | SVM radial        | 87.07%      | 0.806     | Mejor balance entre clases  |
| ClasificaciÃ³n  | RNA (`nnet`)      | 85.78%      | 0.786     | Alto rendimiento en â€œcaraâ€  |
| RegresiÃ³n      | RegresiÃ³n Lineal  | RÂ² 0.89     | MAE \~25K | Simplicidad y buen ajuste   |
| RegresiÃ³n      | RNA (`neuralnet`) | RÂ² 0.83     | MAE \~28K | Flexible, sin sobreajuste   |
| RegresiÃ³n      | Random Forest     | RÂ² 0.98     | MAE \~12K | MÃ¡xima precisiÃ³n, mÃ¡s lento |

> En tÃ©rminos generales:

* **SVM** fue el mejor modelo para **clasificaciÃ³n**.
* **Random Forest** fue el mejor modelo para **regresiÃ³n**.
* **RNA** mostrÃ³ un **buen rendimiento en ambas tareas**, aunque no fue el mÃ¡s eficiente.

### Serie 18: Informe de ConsultorÃ­a TÃ©cnica

* Se elaborÃ³ un **Informe de ConsultorÃ­a TÃ©cnica** para la empresa ficticia **InmoValor**, con el objetivo de **recomendar el mejor modelo predictivo** para estimar el precio de las viviendas en funciÃ³n de datos estructurales.

* El informe incluyÃ³:

  âœ… **Resumen ejecutivo** con el objetivo del anÃ¡lisis y los principales hallazgos.
  âœ… **ComparaciÃ³n de modelos predictivos** (RegresiÃ³n Lineal, SVM, Random Forest, RNA).
  âœ… **JustificaciÃ³n del modelo recomendado**, considerando precisiÃ³n, interpretabilidad y escalabilidad.
  âœ… **GrÃ¡ficos de rendimiento** y tablas comparativas de mÃ©tricas como RÂ², MAE y RMSE.
  âœ… **Recomendaciones estratÃ©gicas** sobre cÃ³mo aplicar el modelo en un sistema de apoyo a decisiones inmobiliarias.

* El modelo recomendado para la empresa fue **Random Forest**, por ser el que alcanzÃ³ el **mejor rendimiento en predicciÃ³n** de `SalePrice`, con un RÂ² cercano a 0.98 y errores mÃ­nimos.

* TambiÃ©n se destacÃ³ el uso potencial de redes neuronales en escenarios con grandes volÃºmenes de datos o relaciones no lineales mÃ¡s complejas.

> ğŸ“Œ **ConclusiÃ³n:** El informe ofreciÃ³ un enfoque claro, tÃ©cnico y orientado a negocios, basado en los resultados obtenidos durante el proyecto, con el objetivo de apoyar decisiones comerciales mÃ¡s precisas.

---

## ğŸ“¦ Limpieza y TransformaciÃ³n de Datos  

- ConversiÃ³n de etiquetas a factores y codificaciÃ³n dummy (`class.ind`).
- ImputaciÃ³n con la mediana, centrado y escalado de variables predictoras.
- VerificaciÃ³n de estructura, dimensiones y balance de clases.
- AlineaciÃ³n de columnas entre `train` y `test`.
- VerificaciÃ³n y balanceo de clases (`SalePriceCat`).

---

## ğŸ›  Herramientas Utilizadas

* **Lenguaje:** R
* **Entorno:** RStudio
* **LibrerÃ­as:** `caret`, `nnet`, `neuralnet`, `ggplot2`, `dplyr`, `Metrics`, `reshape2`
* **Datos:** Kaggle House Prices (`train.csv`, `test.csv`)
* **Control de versiones:** GitHub

---

## ğŸ“¢ Hallazgos Destacados  

âœ”ï¸ Ambos modelos clasifican correctamente mÃ¡s del **85%** de las viviendas.  
âœ”ï¸ La clase **media** sigue siendo la mÃ¡s difÃ­cil de predecir, pero mejora con RNA.
âœ”ï¸ El modelo de RNA clasificÃ³ correctamente mÃ¡s del 87% de los casos.
âœ”ï¸ No se detectÃ³ **sobreajuste**, gracias a la validaciÃ³n cruzada y arquitectura simple.  
âœ”ï¸ El modelo con `neuralnet` fue **ligeramente mÃ¡s preciso**, pero mÃ¡s lento.  
âœ”ï¸ El pipeline queda listo para comparar regresiÃ³n en el siguiente inciso.
